{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "953f10a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PyTorch & torchvision imported successfully\n",
      "‚úì Transformers imported successfully\n",
      "üîß Using device: cuda\n",
      "üîß PyTorch version: 2.5.1+cu121\n",
      "======================================================================\n",
      "ViT Baseline (NO CNN-CBAM, NO QUANTUM)\n",
      "ABLATION STUDY: Pure ViT + Focal Loss Baseline\n",
      "ERBMAHE Dataset Classification\n",
      "Binary Classification: Abnormal vs Normal\n",
      "METHOD 2: K-FOLD (5 folds) WITH SEPARATE TEST SET (10%)\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Base Model: google/vit-base-patch16-224\n",
      "üö´ CNN-CBAM Branch: REMOVED\n",
      "üö´ Quantum Layer: REMOVED\n",
      "‚úÖ Pure ViT Baseline\n",
      "üìä Classes: ['Abnormal', 'Normal']\n",
      "üîÑ K-Fold: 5 folds on 90% data\n",
      "üß™ Test Set: 10% holdout\n",
      "\n",
      "üìÅ Loading dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 686\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 686\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 309\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m CLASSES:\n\u001b[0;32m    308\u001b[0m     class_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, class_name)\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m img_file \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_path):\n\u001b[0;32m    311\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m img_file\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\sidpr\\anaconda3\\envs\\capstone_env\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"ViT Baseline Network (NO CNN-CBAM, NO QUANTUM)\n",
    "ERBMAHE Dataset Classification\n",
    "Binary Classification: Abnormal vs Normal\n",
    "\n",
    "ABLATION STUDY: Only ViT + Focal Loss (baseline for comparison)\n",
    "METHOD 2 K-FOLD WITH SEPARATE TEST SET:\n",
    "- 10% holdout test set (never used during training)\n",
    "- K-Fold cross-validation on remaining 90%\n",
    "- Validation-based early stopping\n",
    "- Best fold model evaluated on test set\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import PyTorch & torchvision\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision import transforms\n",
    "    print(\"‚úì PyTorch & torchvision imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error importing PyTorch/torchvision: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Transformers (ViT)\n",
    "try:\n",
    "    from transformers import ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Transformers...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\"])\n",
    "    from transformers import ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers installed successfully\")\n",
    "\n",
    "# Check GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please run this script on a machine with CUDA-enabled GPU and proper drivers.\")\n",
    "device = torch.device('cuda')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"google/vit-base-patch16-224\"\n",
    "CLASSES = ['Abnormal', 'Normal']\n",
    "N_FOLDS = 5\n",
    "\n",
    "# ============================================================================\n",
    "# CNN-CBAM REMOVED (Ablation Study)\n",
    "# QUANTUM LAYER REMOVED (Ablation Study)\n",
    "# Pure ViT Baseline\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# ViT-Only Model\n",
    "# Pipeline: ViT -> Classifier (no quantum, no CNN-CBAM, no fusion)\n",
    "# ============================================================================\n",
    "class ViTBaseline(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=2):\n",
    "        super(ViTBaseline, self).__init__()\n",
    "        # ViT backbone\n",
    "        self.vit = ViTModel.from_pretrained(model_name)\n",
    "        vit_dim = self.vit.config.hidden_size  # 768\n",
    "\n",
    "        # Direct classifier - no quantum layer, no CNN branch\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(vit_dim, vit_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(vit_dim // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values):\n",
    "        # ViT features\n",
    "        vit_out = self.vit(pixel_values=pixel_values)\n",
    "        vit_features = vit_out.last_hidden_state[:, 0]  # (B, 768)\n",
    "\n",
    "        # Direct to classifier - no quantum, no CNN fusion\n",
    "        logits = self.classifier(vit_features)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# Focal Loss\n",
    "# ============================================================================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - p_t) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_t = self.alpha\n",
    "            else:\n",
    "                alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# ============================================================================\n",
    "# Early Stopping\n",
    "# ============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    def __call__(self, current_score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì Initial best score: {current_score:.4f}\")\n",
    "            return False\n",
    "        if self.mode == 'max':\n",
    "            improved = current_score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            improved = current_score < (self.best_score - self.min_delta)\n",
    "        if improved:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì New best score: {current_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"  No improvement. Patience: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è Early stopping triggered!\")\n",
    "                    print(f\"   Best score: {self.best_score:.4f} at epoch {self.best_epoch}\")\n",
    "        return self.early_stop\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "class ERBMAHEDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, augment=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.augment = augment\n",
    "        self.aug_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.0),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'class_id']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.augment:\n",
    "            image = self.aug_transform(image)\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return pixel_values, label\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN / VALIDATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pixel_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for pixel_values, labels in pbar:\n",
    "            pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "            logits = model(pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1, all_preds, all_labels\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive metrics including sensitivity and specificity\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    sensitivity_class0 = tn / (tn + fn) if (tn + fn) > 0 else 0  # Normal\n",
    "    sensitivity_class1 = tp / (tp + fp) if (tp + fp) > 0 else 0  # Abnormal\n",
    "    specificity_class0 = tn / (tn + fp) if (tn + fp) > 0 else 0  # Normal\n",
    "    specificity_class1 = tp / (tp + fn) if (tp + fn) > 0 else 0  # Abnormal\n",
    "    avg_sensitivity = (sensitivity_class0 + sensitivity_class1) / 2\n",
    "    avg_specificity = (specificity_class0 + specificity_class1) / 2\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy * 100,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'sensitivity_class0': sensitivity_class0,\n",
    "        'sensitivity_class1': sensitivity_class1,\n",
    "        'specificity_class0': specificity_class0,\n",
    "        'specificity_class1': specificity_class1,\n",
    "        'avg_sensitivity': avg_sensitivity,\n",
    "        'avg_specificity': avg_specificity,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ViT Baseline (NO CNN-CBAM, NO QUANTUM)\")\n",
    "    print(\"ABLATION STUDY: Pure ViT + Focal Loss Baseline\")\n",
    "    print(\"ERBMAHE Dataset Classification\")\n",
    "    print(\"Binary Classification: Abnormal vs Normal\")\n",
    "    print(f\"METHOD 2: K-FOLD ({N_FOLDS} folds) WITH SEPARATE TEST SET (10%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    data_path = 'D:/training/archive/ICMR_datasets_ERBMAHE'\n",
    "\n",
    "    print(f\"\\nü§ñ Base Model: {MODEL_NAME}\")\n",
    "    print(f\"üö´ CNN-CBAM Branch: REMOVED\")\n",
    "    print(f\"üö´ Quantum Layer: REMOVED\")\n",
    "    print(f\"‚úÖ Pure ViT Baseline\")\n",
    "    print(f\"üìä Classes: {CLASSES}\")\n",
    "    print(f\"üîÑ K-Fold: {N_FOLDS} folds on 90% data\")\n",
    "    print(f\"üß™ Test Set: 10% holdout\")\n",
    "\n",
    "    print(\"\\nüìÅ Loading dataset...\")\n",
    "    data_list = []\n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                    data_list.append({\n",
    "                        'image_path': os.path.join(class_path, img_file),\n",
    "                        'label': class_name,\n",
    "                        'class_id': CLASSES.index(class_name)\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: {class_path} not found!\")\n",
    "\n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(f\"üìä Total images: {len(df)}\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    # Split: 90% for k-fold, 10% for final test\n",
    "    kfold_df, test_df = train_test_split(df, test_size=0.10, stratify=df['class_id'], random_state=42)\n",
    "\n",
    "    print(f\"\\nüìä Dataset split:\")\n",
    "    print(f\"  K-Fold data: {len(kfold_df)} ({len(kfold_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Test data:   {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "    # Class weights for focal loss\n",
    "    class_counts = kfold_df['label'].value_counts().sort_index().values\n",
    "    total_samples = len(kfold_df)\n",
    "    class_weights = total_samples / (len(CLASSES) * class_counts)\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(f\"\\n‚öñÔ∏è Class weights for Focal Loss:\")\n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        print(f\"  {class_name}: {class_weights[i]:.4f}\")\n",
    "\n",
    "    print(f\"\\nüîß Loading ViT processor...\")\n",
    "    processor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    all_fold_histories = []\n",
    "\n",
    "    batch_size = 16\n",
    "    num_epochs = 50\n",
    "\n",
    "    print(f\"\\n‚öôÔ∏è Training configuration:\")\n",
    "    print(f\"  Max epochs per fold: {num_epochs}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Early stopping patience: 10 epochs\")\n",
    "    print(f\"  Learning rate (ViT): 1e-5\")\n",
    "    print(f\"  Learning rate (Classifier): 1e-4\")\n",
    "    print(f\"  CNN-CBAM: REMOVED\")\n",
    "    print(f\"  Quantum Layer: REMOVED\")\n",
    "    print(f\"  Scheduler: CosineAnnealingLR\")\n",
    "    print(f\"  Loss: Focal Loss (gamma=2.0)\")\n",
    "    print(f\"  Strategy: Method 2 with separate test set\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # K-FOLD CROSS-VALIDATION\n",
    "    # ============================================================================\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(kfold_df, kfold_df['class_id'])):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"FOLD {fold_idx + 1}/{N_FOLDS}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        train_df = kfold_df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df   = kfold_df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        print(f\"\\nüìä Fold {fold_idx + 1} split:\")\n",
    "        print(f\"  Train:      {len(train_df)} ({len(train_df)/len(kfold_df)*100:.1f}% of k-fold data)\")\n",
    "        print(f\"  Validation: {len(val_df)} ({len(val_df)/len(kfold_df)*100:.1f}% of k-fold data)\")\n",
    "\n",
    "        train_dataset = ERBMAHEDataset(train_df, processor=processor, augment=True)\n",
    "        val_dataset   = ERBMAHEDataset(val_df,   processor=processor, augment=False)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        print(f\"\\nü§ñ Creating ViT Baseline (no CNN-CBAM, no Quantum) for Fold {fold_idx + 1}...\")\n",
    "        model = ViTBaseline(model_name=MODEL_NAME, num_classes=len(CLASSES)).to(device)\n",
    "\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        if fold_idx == 0:\n",
    "            total_params     = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            print(f\"‚úì Total parameters:     {total_params:,}\")\n",
    "            print(f\"‚úì Trainable parameters: {trainable_params:,}\")\n",
    "            print(f\"‚úì CNN-CBAM parameters:  0 (REMOVED)\")\n",
    "            print(f\"‚úì Quantum parameters:   0 (REMOVED)\")\n",
    "            print(f\"‚úì Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "        def build_optimizer(model):\n",
    "            groups = []\n",
    "            vit_params = [p for p in model.vit.parameters() if p.requires_grad]\n",
    "            if vit_params:\n",
    "                groups.append({'params': vit_params, 'lr': 1e-5})\n",
    "            clf_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "            if clf_params:\n",
    "                groups.append({'params': clf_params, 'lr': 1e-4})\n",
    "            if not groups:\n",
    "                groups = [{'params': [p for p in model.parameters() if p.requires_grad], 'lr': 1e-4}]\n",
    "            return torch.optim.AdamW(groups, weight_decay=0.01)\n",
    "\n",
    "        criterion      = FocalLoss(alpha=class_weights, gamma=2.0, reduction='mean')\n",
    "        optimizer      = build_optimizer(model)\n",
    "        scheduler      = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "        early_stopping = EarlyStopping(patience=10, min_delta=0.001, mode='max', verbose=True)\n",
    "\n",
    "        best_val_acc = 0.0\n",
    "        fold_history = {\n",
    "            'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "            'val_loss':   [], 'val_acc':   [], 'val_f1':   []\n",
    "        }\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nFold {fold_idx + 1} - Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "            train_loss, train_acc, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss,   val_acc,   val_f1, _, _ = validate(model, val_loader, criterion, device)\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            fold_history['train_loss'].append(train_loss)\n",
    "            fold_history['train_acc'].append(train_acc)\n",
    "            fold_history['train_f1'].append(train_f1)\n",
    "            fold_history['val_loss'].append(val_loss)\n",
    "            fold_history['val_acc'].append(val_acc)\n",
    "            fold_history['val_f1'].append(val_f1)\n",
    "\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"\\nResults:\")\n",
    "            print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, F1: {train_f1:.4f}\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}\")\n",
    "            print(f\"  Learning Rate (group0): {current_lr:.2e}\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'fold{fold_idx+1}_vitonly_best.pth')\n",
    "                print(f\"  üíæ Best model saved! (Val Acc: {best_val_acc:.2f}%)\")\n",
    "\n",
    "            if early_stopping(val_acc, epoch):\n",
    "                print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "        # Final validation evaluation\n",
    "        print(f\"\\nüìä EVALUATING FOLD {fold_idx + 1}\")\n",
    "        print(\"=\"*70)\n",
    "        model.load_state_dict(torch.load(f'fold{fold_idx+1}_vitonly_best.pth'))\n",
    "        val_loss, val_acc, val_f1, y_pred, y_true = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        metrics = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nüìà Fold {fold_idx + 1} Validation Results:\")\n",
    "        print(f\"  Accuracy:               {metrics['accuracy']:.2f}%\")\n",
    "        print(f\"  Precision:              {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall:                 {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1 Score:               {metrics['f1']:.4f}\")\n",
    "        print(f\"  Sensitivity (Normal):   {metrics['sensitivity_class0']:.4f}\")\n",
    "        print(f\"  Sensitivity (Abnormal): {metrics['sensitivity_class1']:.4f}\")\n",
    "        print(f\"  Specificity (Normal):   {metrics['specificity_class0']:.4f}\")\n",
    "        print(f\"  Specificity (Abnormal): {metrics['specificity_class1']:.4f}\")\n",
    "        print(f\"  Avg Sensitivity:        {metrics['avg_sensitivity']:.4f}\")\n",
    "        print(f\"  Avg Specificity:        {metrics['avg_specificity']:.4f}\")\n",
    "\n",
    "        fold_results.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'val_acc':         metrics['accuracy'],\n",
    "            'val_precision':   metrics['precision'],\n",
    "            'val_recall':      metrics['recall'],\n",
    "            'val_f1':          metrics['f1'],\n",
    "            'val_sensitivity': metrics['avg_sensitivity'],\n",
    "            'val_specificity': metrics['avg_specificity'],\n",
    "            'best_val_acc':    best_val_acc,\n",
    "            'epochs_trained':  len(fold_history['train_loss']),\n",
    "            'model_path':      f'fold{fold_idx+1}_vitonly_best.pth',\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'metrics': metrics\n",
    "        })\n",
    "\n",
    "        all_fold_histories.append(fold_history)\n",
    "\n",
    "        # Per-fold confusion matrix\n",
    "        cm = metrics['confusion_matrix']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "        plt.title(f'Fold {fold_idx + 1} - Confusion Matrix (ViT Only)\\n(Val Acc: {metrics[\"accuracy\"]:.2f}%)')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'fold{fold_idx+1}_vitonly_confusion_matrix.png', dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"‚úì Confusion matrix saved\")\n",
    "\n",
    "        # Enhanced visualizations for Fold 1 only\n",
    "        if fold_idx == 0:\n",
    "            print(f\"\\nüìä Creating enhanced visualizations for Fold 1...\")\n",
    "            epochs_range = range(1, len(fold_history['train_loss']) + 1)\n",
    "\n",
    "            # 1. Training / Validation curves\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "            axes[0].plot(epochs_range, fold_history['train_loss'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[0].plot(epochs_range, fold_history['val_loss'],   'r-s', label='Val',   linewidth=2, markersize=4)\n",
    "            axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[0].set_ylabel('Loss', fontsize=12)\n",
    "            axes[0].set_title('Fold 1 - Loss (ViT Only)', fontsize=14, fontweight='bold')\n",
    "            axes[0].legend(fontsize=10)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "            axes[1].plot(epochs_range, fold_history['train_acc'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[1].plot(epochs_range, fold_history['val_acc'],   'r-s', label='Val',   linewidth=2, markersize=4)\n",
    "            axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            axes[1].set_title('Fold 1 - Accuracy (ViT Only)', fontsize=14, fontweight='bold')\n",
    "            axes[1].legend(fontsize=10)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "            axes[2].plot(epochs_range, fold_history['train_f1'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[2].plot(epochs_range, fold_history['val_f1'],   'r-s', label='Val',   linewidth=2, markersize=4)\n",
    "            axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[2].set_ylabel('F1 Score', fontsize=12)\n",
    "            axes[2].set_title('Fold 1 - F1 Score (ViT Only)', fontsize=14, fontweight='bold')\n",
    "            axes[2].legend(fontsize=10)\n",
    "            axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_vitonly_training_curves.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Training curves saved\")\n",
    "\n",
    "            # 2. Detailed confusion matrix\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "            annotations = np.empty_like(cm).astype(str)\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    annotations[i, j] = f'{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)'\n",
    "            sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues',\n",
    "                        xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "                        cbar_kws={'label': 'Count'}, ax=ax)\n",
    "            ax.set_title(f'Fold 1 - Detailed Confusion Matrix (ViT Only)\\nVal Acc: {metrics[\"accuracy\"]:.2f}%',\n",
    "                         fontsize=14, fontweight='bold')\n",
    "            ax.set_ylabel('True Label', fontsize=12)\n",
    "            ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_vitonly_confusion_detailed.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Detailed confusion matrix saved\")\n",
    "\n",
    "            # 3. Metrics summary bar chart\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            metric_names  = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Sensitivity', 'Specificity']\n",
    "            metric_values = [\n",
    "                metrics['accuracy'],\n",
    "                metrics['precision']        * 100,\n",
    "                metrics['recall']           * 100,\n",
    "                metrics['f1']               * 100,\n",
    "                metrics['avg_sensitivity']  * 100,\n",
    "                metrics['avg_specificity']  * 100\n",
    "            ]\n",
    "            colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "            bars = ax.bar(metric_names, metric_values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            for bar, value in zip(bars, metric_values):\n",
    "                ax.text(bar.get_x() + bar.get_width() / 2., bar.get_height(),\n",
    "                        f'{value:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "            ax.set_ylabel('Score (%)', fontsize=12)\n",
    "            ax.set_title('Fold 1 - Validation Metrics Summary (ViT Only)', fontsize=14, fontweight='bold')\n",
    "            ax.set_ylim([0, 105])\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            plt.xticks(rotation=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_vitonly_metrics_summary.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Metrics summary saved\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # SUMMARY ACROSS FOLDS\n",
    "    # ============================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    accuracies    = [r['val_acc']         for r in fold_results]\n",
    "    precisions    = [r['val_precision']   for r in fold_results]\n",
    "    recalls       = [r['val_recall']      for r in fold_results]\n",
    "    f1_scores     = [r['val_f1']          for r in fold_results]\n",
    "    sensitivities = [r['val_sensitivity'] for r in fold_results]\n",
    "    specificities = [r['val_specificity'] for r in fold_results]\n",
    "\n",
    "    print(f\"\\nüìà Cross-Validation Results ({N_FOLDS} folds):\")\n",
    "    print(f\"  Accuracy:     {np.mean(accuracies):.2f}%  ¬± {np.std(accuracies):.2f}%\")\n",
    "    print(f\"  Precision:    {np.mean(precisions):.4f} ¬± {np.std(precisions):.4f}\")\n",
    "    print(f\"  Recall:       {np.mean(recalls):.4f} ¬± {np.std(recalls):.4f}\")\n",
    "    print(f\"  F1 Score:     {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "    print(f\"  Sensitivity:  {np.mean(sensitivities):.4f} ¬± {np.std(sensitivities):.4f}\")\n",
    "    print(f\"  Specificity:  {np.mean(specificities):.4f} ¬± {np.std(specificities):.4f}\")\n",
    "\n",
    "    best_fold_idx = np.argmax(accuracies)\n",
    "    best_fold     = fold_results[best_fold_idx]\n",
    "    print(f\"\\nüèÜ Best Fold: {best_fold['fold']} (Val Acc: {best_fold['val_acc']:.2f}%)\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # EVALUATE BEST MODEL ON HOLDOUT TEST SET\n",
    "    # ============================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üß™ EVALUATING BEST MODEL ON HOLDOUT TEST SET\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(f\"\\nüìä Loading best model from Fold {best_fold['fold']}...\")\n",
    "    best_model = ViTBaseline(model_name=MODEL_NAME, num_classes=len(CLASSES)).to(device)\n",
    "    best_model.load_state_dict(torch.load(best_fold['model_path']))\n",
    "\n",
    "    test_dataset = ERBMAHEDataset(test_df, processor=processor, augment=False)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2.0, reduction='mean')\n",
    "    test_loss, test_acc, test_f1, test_pred, test_true = validate(best_model, test_loader, criterion, device)\n",
    "    test_metrics = calculate_metrics(test_true, test_pred)\n",
    "\n",
    "    print(f\"\\nüìà Test Set Results (Best Model ‚Äî Fold {best_fold['fold']}):\")\n",
    "    print(f\"  Accuracy:               {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Precision:              {test_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:                 {test_metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:               {test_metrics['f1']:.4f}\")\n",
    "    print(f\"  Sensitivity (Normal):   {test_metrics['sensitivity_class0']:.4f}\")\n",
    "    print(f\"  Sensitivity (Abnormal): {test_metrics['sensitivity_class1']:.4f}\")\n",
    "    print(f\"  Specificity (Normal):   {test_metrics['specificity_class0']:.4f}\")\n",
    "    print(f\"  Specificity (Abnormal): {test_metrics['specificity_class1']:.4f}\")\n",
    "    print(f\"  Avg Sensitivity:        {test_metrics['avg_sensitivity']:.4f}\")\n",
    "    print(f\"  Avg Specificity:        {test_metrics['avg_specificity']:.4f}\")\n",
    "\n",
    "    # Test confusion matrix\n",
    "    test_cm = test_metrics['confusion_matrix']\n",
    "    test_cm_percent = test_cm.astype('float') / test_cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    test_annotations = np.empty_like(test_cm).astype(str)\n",
    "    for i in range(test_cm.shape[0]):\n",
    "        for j in range(test_cm.shape[1]):\n",
    "            test_annotations[i, j] = f'{test_cm[i, j]}\\n({test_cm_percent[i, j]:.1f}%)'\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(test_cm, annot=test_annotations, fmt='', cmap='Greens',\n",
    "                xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Test Set Confusion Matrix (ViT Only)\\n'\n",
    "              f'Best Model Fold {best_fold[\"fold\"]} ‚Äî Acc: {test_metrics[\"accuracy\"]:.2f}%',\n",
    "              fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('test_vitonly_confusion_matrix.png', dpi=150)\n",
    "    plt.close()\n",
    "    print(\"\\n‚úì Test confusion matrix saved\")\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    results_df.to_csv('kfold_vitonly_results.csv', index=False)\n",
    "    print(\"‚úì Results saved to CSV\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìä Final Summary:\")\n",
    "    print(f\"  Model: ViT Baseline (NO CNN-CBAM, NO QUANTUM)\")\n",
    "    print(f\"  Ablation: Pure ViT + Focal Loss\")\n",
    "    print(f\"  Dataset: ERBMAHE (Abnormal vs Normal)\")\n",
    "    print(f\"  Strategy: Method 2 K-Fold with 10% Test Set\")\n",
    "    print(f\"  K-Fold CV Accuracy: {np.mean(accuracies):.2f}% ¬± {np.std(accuracies):.2f}%\")\n",
    "    print(f\"  Test Set Accuracy:  {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Test Set F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0985dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
