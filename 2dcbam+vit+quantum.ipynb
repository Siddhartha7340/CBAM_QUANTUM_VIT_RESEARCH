{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4912b10b",
   "metadata": {},
   "source": [
    "## double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe104b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ViT + CNN-CBAM + Fusion + Quantum Hybrid Network\n",
    "ERBMAHE Dataset Classification\n",
    "Binary Classification: Abnormal vs Normal\n",
    "\n",
    "MODIFICATIONS:\n",
    "- Using ORIGINAL 2D-CBAM (Channel + Spatial Attention on 2D feature maps)\n",
    "- Train whole model from epoch 1 (no staged freezing)\n",
    "- Keeps Focal Loss, EarlyStopping, CosineAnnealingLR, Quantum layer, everything else.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import PyTorch & torchvision\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision import transforms, models\n",
    "    print(\"‚úì PyTorch & torchvision imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error importing PyTorch/torchvision: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Transformers (ViT)\n",
    "try:\n",
    "    from transformers import ViTForImageClassification, ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Transformers...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\"])\n",
    "    from transformers import ViTForImageClassification, ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers installed successfully\")\n",
    "\n",
    "# PennyLane (quantum)\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    print(\"‚úì PennyLane imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing PennyLane...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pennylane\"])\n",
    "    import pennylane as qml\n",
    "    print(\"‚úì PennyLane installed successfully\")\n",
    "\n",
    "# Check GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please run this script on a machine with CUDA-enabled GPU and proper drivers.\")\n",
    "device = torch.device('cuda')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"google/vit-base-patch16-224\"\n",
    "CLASSES = ['Abnormal', 'Normal']\n",
    "N_QUBITS = 4  # quantum qubits\n",
    "\n",
    "# ============================================================================\n",
    "# ORIGINAL 2D-CBAM (Channel Attention + Spatial Attention)\n",
    "# ============================================================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(x_cat)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Channel attention\n",
    "        x = x * self.channel_attention(x)\n",
    "        # Spatial attention\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "# ============================================================================\n",
    "# CNN + CBAM BRANCH (ResNet18 backbone -> CBAM -> Global Pool)\n",
    "# ============================================================================\n",
    "class CNN_CBAM_Branch(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CNN_CBAM_Branch, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        # Extract features up to layer4 (before avgpool)\n",
    "        # ResNet structure: conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])  # up to layer4 (outputs 512 x 7 x 7)\n",
    "        \n",
    "        # Apply CBAM on the 2D feature maps\n",
    "        self.cbam = CBAM(512, reduction=16, kernel_size=7)\n",
    "        \n",
    "        # Global average pooling to get 1D features\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (B, 3, H, W)\n",
    "        feat = self.backbone(x)          # (B, 512, 7, 7)\n",
    "        feat = self.cbam(feat)           # (B, 512, 7, 7) with attention applied\n",
    "        feat = self.global_pool(feat)    # (B, 512, 1, 1)\n",
    "        feat = feat.view(feat.size(0), -1)  # (B, 512)\n",
    "        return feat\n",
    "\n",
    "# ============================================================================\n",
    "# Quantum Circuit & Layer\n",
    "# ============================================================================\n",
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits=4):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.dev = qml.device('default.qubit', wires=n_qubits)\n",
    "    \n",
    "    def circuit(self, inputs, weights):\n",
    "        for i in range(self.n_qubits):\n",
    "            qml.RX(inputs[i], wires=i)\n",
    "            qml.RZ(inputs[i], wires=i)\n",
    "        for i in range(self.n_qubits - 1):\n",
    "            qml.CRX(weights[i], wires=[i, i+1])\n",
    "        qml.CRX(weights[self.n_qubits-1], wires=[self.n_qubits-1, 0])\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "    \n",
    "    def create_qnode(self, weights):\n",
    "        @qml.qnode(self.dev, interface='torch')\n",
    "        def qnode(inputs):\n",
    "            return self.circuit(inputs, weights)\n",
    "        return qnode\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, input_dim, n_qubits=4):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.feature_compress = nn.Linear(input_dim, n_qubits)\n",
    "        self.q_weights = nn.Parameter(torch.randn(n_qubits) * 0.01)\n",
    "        self.qc = QuantumCircuit(n_qubits)\n",
    "        self.feature_expand = nn.Linear(n_qubits, input_dim)\n",
    "        self.skip_alpha = nn.Parameter(torch.tensor(0.1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        batch_size = x.size(0)\n",
    "        x_compressed = self.feature_compress(x)  # (B, n_qubits)\n",
    "        qnode = self.qc.create_qnode(self.q_weights)\n",
    "        q_out_list = []\n",
    "        for i in range(batch_size):\n",
    "            q_input = torch.tanh(x_compressed[i]) * np.pi\n",
    "            q_result = torch.stack(qnode(q_input))\n",
    "            q_result = q_result.float()\n",
    "            q_out_list.append(q_result)\n",
    "        q_out = torch.stack(q_out_list)  # (B, n_qubits)\n",
    "        output = self.feature_expand(q_out)  # (B, input_dim)\n",
    "        output = output + self.skip_alpha * identity\n",
    "        return output\n",
    "\n",
    "# ============================================================================\n",
    "# Fusion Hybrid Model (ViT + CNN-CBAM -> Fusion -> Quantum -> Classifier)\n",
    "# ============================================================================\n",
    "class ViTQuantumHybrid(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=2, n_qubits=4):\n",
    "        super(ViTQuantumHybrid, self).__init__()\n",
    "        # ViT backbone\n",
    "        self.vit = ViTModel.from_pretrained(model_name)\n",
    "        vit_dim = self.vit.config.hidden_size  # typically 768\n",
    "        \n",
    "        # CNN branch with 2D-CBAM\n",
    "        self.cnn_branch = CNN_CBAM_Branch(pretrained=True)\n",
    "        cnn_dim = 512\n",
    "        \n",
    "        # Fusion projection\n",
    "        self.fusion_proj = nn.Linear(vit_dim + cnn_dim, vit_dim)\n",
    "        \n",
    "        # Quantum enhancement\n",
    "        self.quantum_layer = QuantumLayer(vit_dim, n_qubits=n_qubits)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(vit_dim, vit_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(vit_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        \"\"\"\n",
    "        pixel_values: tensor (B, 3, H, W) ‚Äî produced by ViTImageProcessor\n",
    "        \"\"\"\n",
    "        # ViT features\n",
    "        vit_out = self.vit(pixel_values=pixel_values)\n",
    "        vit_features = vit_out.last_hidden_state[:, 0]  # (B, vit_dim)\n",
    "\n",
    "        # CNN features with 2D-CBAM attention\n",
    "        cnn_features = self.cnn_branch(pixel_values)    # (B, 512)\n",
    "\n",
    "        # Fuse and project\n",
    "        fused = torch.cat([vit_features, cnn_features], dim=1)  # (B, vit_dim + 512)\n",
    "        fused = self.fusion_proj(fused)  # (B, vit_dim)\n",
    "\n",
    "        # Quantum enhancement\n",
    "        quantum_features = self.quantum_layer(fused)  # (B, vit_dim)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(quantum_features)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# Focal Loss\n",
    "# ============================================================================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - p_t) ** self.gamma * ce_loss\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_t = self.alpha\n",
    "            else:\n",
    "                alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# ============================================================================\n",
    "# Early Stopping\n",
    "# ============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def __call__(self, current_score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì Initial best score: {current_score:.4f}\")\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            improved = current_score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            improved = current_score < (self.best_score - self.min_delta)\n",
    "        \n",
    "        if improved:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì New best score: {current_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"  No improvement. Patience: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è Early stopping triggered!\")\n",
    "                    print(f\"   Best score: {self.best_score:.4f} at epoch {self.best_epoch}\")\n",
    "        return self.early_stop\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "class ERBMAHEDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, augment=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.augment = augment\n",
    "        self.aug_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.0),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'class_id']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.augment:\n",
    "            image = self.aug_transform(image)\n",
    "        \n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return pixel_values, label\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN / VALIDATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pixel_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for pixel_values, labels in pbar:\n",
    "            pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "            logits = model(pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1, all_preds, all_labels\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ViT + CNN-2D-CBAM + Fusion + Quantum Hybrid Network\")\n",
    "    print(\"ERBMAHE Dataset Classification\")\n",
    "    print(\"Binary Classification: Abnormal vs Normal\")\n",
    "    print(\"USING ORIGINAL 2D-CBAM + FOCAL LOSS + QUANTUM ENHANCEMENT\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Dataset path (update if needed)\n",
    "    data_path = 'D:/training/archive/ICMR_datasets_ERBMAHE'\n",
    "\n",
    "    print(f\"\\nü§ñ Base Model: {MODEL_NAME}\")\n",
    "    print(f\"‚öõÔ∏è  Quantum Qubits: {N_QUBITS}\")\n",
    "    print(f\"üìä Classes: {CLASSES}\")\n",
    "\n",
    "    print(\"\\nüìÅ Loading dataset...\")\n",
    "    data_list = []\n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                    data_list.append({\n",
    "                        'image_path': os.path.join(class_path, img_file),\n",
    "                        'label': class_name,\n",
    "                        'class_id': CLASSES.index(class_name)\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: {class_path} not found!\")\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(f\"üìä Total images: {len(df)}\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    # Class weights for focal loss\n",
    "    class_counts = df['label'].value_counts().sort_index().values\n",
    "    total_samples = len(df)\n",
    "    class_weights = total_samples / (len(CLASSES) * class_counts)\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(f\"\\n‚öñÔ∏è Class weights for Focal Loss:\")\n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        print(f\"  {class_name}: {class_weights[i]:.4f}\")\n",
    "\n",
    "    # Splits\n",
    "    temp_df, test_df = train_test_split(df, test_size=0.10, stratify=df['class_id'], random_state=42)\n",
    "    train_df, val_df = train_test_split(temp_df, test_size=0.111111, stratify=temp_df['class_id'], random_state=42)\n",
    "    print(f\"\\nüìä Dataset split:\")\n",
    "    print(f\"  Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "    # ViT processor\n",
    "    print(f\"\\nüîß Loading ViT processor...\")\n",
    "    processor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # Datasets & dataloaders\n",
    "    train_dataset = ERBMAHEDataset(train_df, processor=processor, augment=True)\n",
    "    val_dataset = ERBMAHEDataset(val_df, processor=processor, augment=False)\n",
    "    test_dataset = ERBMAHEDataset(test_df, processor=processor, augment=False)\n",
    "    \n",
    "    batch_size = 16\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # Create model\n",
    "    print(f\"\\nü§ñ Creating Hybrid ViT + CNN-2D-CBAM + Fusion + Quantum Model...\")\n",
    "    model = ViTQuantumHybrid(model_name=MODEL_NAME, num_classes=len(CLASSES), n_qubits=N_QUBITS).to(device)\n",
    "\n",
    "    # Ensure whole model is trainable from epoch 1\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    quantum_params = sum(p.numel() for p in model.quantum_layer.parameters())\n",
    "\n",
    "    print(f\"‚úì Total parameters: {total_params:,}\")\n",
    "    print(f\"‚úì Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"‚úì Quantum layer parameters: {quantum_params:,}\")\n",
    "    print(f\"‚úì Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "    # Criterion\n",
    "    criterion = FocalLoss(alpha=class_weights, gamma=2.0, reduction='mean')\n",
    "\n",
    "    # Build optimizer\n",
    "    def build_optimizer(model):\n",
    "        groups = []\n",
    "        # ViT params\n",
    "        vit_params = [p for p in model.vit.parameters() if p.requires_grad]\n",
    "        if vit_params:\n",
    "            groups.append({'params': vit_params, 'lr': 1e-5})\n",
    "        # CNN branch\n",
    "        cnn_params = [p for p in model.cnn_branch.parameters() if p.requires_grad]\n",
    "        if cnn_params:\n",
    "            groups.append({'params': cnn_params, 'lr': 2e-4})\n",
    "        # Quantum layer\n",
    "        q_params = [p for p in model.quantum_layer.parameters() if p.requires_grad]\n",
    "        if q_params:\n",
    "            groups.append({'params': q_params, 'lr': 5e-5})\n",
    "        # Classifier\n",
    "        clf_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "        if clf_params:\n",
    "            groups.append({'params': clf_params, 'lr': 1e-4})\n",
    "        # Fallback\n",
    "        if not groups:\n",
    "            groups = [{'params': [p for p in model.parameters() if p.requires_grad], 'lr': 1e-4}]\n",
    "        opt = torch.optim.AdamW(groups, weight_decay=0.01)\n",
    "        return opt\n",
    "\n",
    "    optimizer = build_optimizer(model)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=1e-6)\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001, mode='max', verbose=True)\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    print(f\"\\n‚öôÔ∏è Training configuration:\")\n",
    "    print(f\"  Epochs: {num_epochs}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Training: Whole model from epoch 1\")\n",
    "    print(f\"  CBAM Type: Original 2D-CBAM (Channel + Spatial Attention)\")\n",
    "    print(f\"  Learning rate (ViT backbone): 1e-5\")\n",
    "    print(f\"  Learning rate (CNN backbone): 2e-4\")\n",
    "    print(f\"  Learning rate (Quantum layer): 5e-5\")\n",
    "    print(f\"  Learning rate (Classifier): 1e-4\")\n",
    "    print(f\"  Scheduler: CosineAnnealingLR\")\n",
    "    print(f\"  Early stopping patience: {early_stopping.patience}\")\n",
    "    print(f\"  Loss function: Focal Loss (gamma=2.0)\")\n",
    "\n",
    "    # History\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        train_loss, train_acc, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, val_f1, _, _ = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_f1'].append(train_f1)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, F1: {train_f1:.4f}\")\n",
    "        print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}\")\n",
    "        print(f\"  Learning Rate (group0): {current_lr:.2e}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'vit_quantum_hybrid_2d_cbam_best.pth')\n",
    "            print(f\"  üíæ Best model saved! (Val Acc: {best_val_acc:.2f}%)\")\n",
    "\n",
    "        if early_stopping(val_acc, epoch+1):\n",
    "            print(f\"\\nüõë Training stopped early at epoch {epoch+1}\")\n",
    "            print(f\"   Best validation accuracy: {early_stopping.best_score:.2f}% at epoch {early_stopping.best_epoch}\")\n",
    "            break\n",
    "\n",
    "    # TEST EVALUATION\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä EVALUATING ON TEST SET\")\n",
    "    print(\"=\"*70)\n",
    "    model.load_state_dict(torch.load('vit_quantum_hybrid_2d_cbam_best.pth'))\n",
    "    test_loss, test_acc, test_f1, y_pred, y_true = validate(model, test_loader, criterion, device)\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"\\nüìà Test Results:\")\n",
    "    print(f\"  Accuracy:  {test_acc:.2f}%\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "\n",
    "    # Per-class metrics\n",
    "    print(\"\\nüìä Per-Class Performance:\")\n",
    "    p_class, r_class, f1_class, s_class = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  Precision: {p_class[i]:.4f}\")\n",
    "        print(f\"  Recall:    {r_class[i]:.4f}\")\n",
    "        print(f\"  F1 Score:  {f1_class[i]:.4f}\")\n",
    "        print(f\"  Support:   {s_class[i]}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.title('ViT + CNN-2D-CBAM + Fusion + Quantum - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('vit_quantum_2d_cbam_confusion_matrix.png', dpi=150)\n",
    "    print(\"\\n‚úì Confusion matrix saved\")\n",
    "\n",
    "    # Training history plots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    axes[0].plot(history['train_loss'], label='Train', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].plot(history['train_acc'], label='Train', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[2].plot(history['train_f1'], label='Train', marker='o')\n",
    "    axes[2].plot(history['val_f1'], label='Val', marker='s')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('F1 Score')\n",
    "    axes[2].set_title('Training and Validation F1 Score')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('vit_quantum_2d_cbam_training_history.png', dpi=150)\n",
    "    print(\"‚úì Training history saved\")\n",
    "\n",
    "    # Specificity calculation\n",
    "    tn = cm[0, 0]\n",
    "    fp = cm[0, 1]\n",
    "    fn = cm[1, 0]\n",
    "    tp = cm[1, 1]\n",
    "    specificity_normal = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    specificity_abnormal = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    avg_specificity = (specificity_normal + specificity_abnormal) / 2\n",
    "\n",
    "    print(f\"\\nüìä Additional Metrics:\")\n",
    "    print(f\"  Specificity (Normal):   {specificity_normal:.4f}\")\n",
    "    print(f\"  Specificity (Abnormal): {specificity_abnormal:.4f}\")\n",
    "    print(f\"  Average Specificity:    {avg_specificity:.4f}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìä Final Summary:\")\n",
    "    print(f\"  Model: ViT + CNN-2D-CBAM + Fusion + Quantum ({N_QUBITS} qubits)\")\n",
    "    print(f\"  CBAM Type: Original 2D-CBAM (Channel + Spatial Attention)\")\n",
    "    print(f\"  Dataset: ERBMAHE (Abnormal vs Normal)\")\n",
    "    print(f\"  Loss Function: Focal Loss (gamma=2.0)\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Test F1 Score: {test_f1:.4f}\")\n",
    "    print(f\"  Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"  Total Parameters: {total_params:,}\")\n",
    "    print(f\"  Quantum Parameters: {quantum_params:,}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2081e",
   "metadata": {},
   "source": [
    "## KFOLD 2DCBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c016485f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì PyTorch & torchvision imported successfully\n",
      "‚úì Transformers imported successfully\n",
      "‚úì PennyLane imported successfully\n",
      "üîß Using device: cuda\n",
      "üîß PyTorch version: 2.5.1+cu121\n",
      "======================================================================\n",
      "ViT + CNN-2D-CBAM + Fusion + Quantum Hybrid Network\n",
      "ERBMAHE Dataset Classification\n",
      "Binary Classification: Abnormal vs Normal\n",
      "METHOD 2: K-FOLD (5 folds) WITH SEPARATE TEST SET (10%)\n",
      "======================================================================\n",
      "\n",
      "ü§ñ Base Model: google/vit-base-patch16-224\n",
      "‚öõÔ∏è  Quantum Qubits: 4\n",
      "üìä Classes: ['Abnormal', 'Normal']\n",
      "üîÑ K-Fold: 5 folds on 90% data\n",
      "üß™ Test Set: 10% holdout\n",
      "\n",
      "üìÅ Loading dataset...\n",
      "üìä Total images: 1981\n",
      "\n",
      "Class distribution:\n",
      "label\n",
      "Normal      1270\n",
      "Abnormal     711\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìä Dataset split:\n",
      "  K-Fold data: 1782 (90.0%)\n",
      "  Test data:   199 (10.0%)\n",
      "\n",
      "‚öñÔ∏è Class weights for Focal Loss:\n",
      "  Abnormal: 1.3922\n",
      "  Normal: 0.7802\n",
      "\n",
      "üîß Loading ViT processor...\n",
      "\n",
      "‚öôÔ∏è Training configuration:\n",
      "  Max epochs per fold: 50\n",
      "  Batch size: 16\n",
      "  Early stopping patience: 10 epochs\n",
      "  Learning rate (ViT): 1e-5\n",
      "  Learning rate (CNN): 2e-4\n",
      "  Learning rate (Quantum): 5e-5\n",
      "  Learning rate (Classifier): 1e-4\n",
      "  Scheduler: CosineAnnealingLR\n",
      "  Loss: Focal Loss (gamma=2.0)\n",
      "  Strategy: Method 2 with separate test set\n",
      "\n",
      "======================================================================\n",
      "FOLD 1/5\n",
      "======================================================================\n",
      "\n",
      "üìä Fold 1 split:\n",
      "  Train:      1425 (80.0% of k-fold data)\n",
      "  Validation: 357 (20.0% of k-fold data)\n",
      "\n",
      "ü§ñ Creating model for Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Total parameters: 98,885,421\n",
      "‚úì Trainable parameters: 98,885,421\n",
      "‚úì Quantum layer parameters: 6,921\n",
      "‚úì Model size: 377.22 MB\n",
      "\n",
      "Fold 1 - Epoch 1/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:10<00:00,  4.12s/it, loss=0.0947, acc=84.56%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.82s/it, loss=0.0537, acc=94.40%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0947, Acc: 84.56%, F1: 0.8465\n",
      "  Val   - Loss: 0.0537, Acc: 94.40%, F1: 0.9439\n",
      "  Learning Rate (group0): 9.99e-06\n",
      "  üíæ Best model saved! (Val Acc: 94.40%)\n",
      "  ‚úì Initial best score: 94.3978\n",
      "\n",
      "Fold 1 - Epoch 2/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:34<00:00,  3.72s/it, loss=0.0611, acc=90.53%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.72s/it, loss=0.1056, acc=89.08%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0611, Acc: 90.53%, F1: 0.9060\n",
      "  Val   - Loss: 0.1056, Acc: 89.08%, F1: 0.8860\n",
      "  Learning Rate (group0): 9.96e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 3/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:37<00:00,  3.75s/it, loss=0.0442, acc=93.89%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0355, acc=95.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0442, Acc: 93.89%, F1: 0.9392\n",
      "  Val   - Loss: 0.0355, Acc: 95.24%, F1: 0.9529\n",
      "  Learning Rate (group0): 9.92e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.24%)\n",
      "  ‚úì New best score: 95.2381\n",
      "\n",
      "Fold 1 - Epoch 4/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.83s/it, loss=0.0335, acc=96.63%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.73s/it, loss=0.0424, acc=95.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0335, Acc: 96.63%, F1: 0.9664\n",
      "  Val   - Loss: 0.0424, Acc: 95.24%, F1: 0.9523\n",
      "  Learning Rate (group0): 9.86e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 5/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:46<00:00,  3.86s/it, loss=0.0235, acc=96.42%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:38<00:00,  1.66s/it, loss=0.0526, acc=91.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0235, Acc: 96.42%, F1: 0.9644\n",
      "  Val   - Loss: 0.0526, Acc: 91.88%, F1: 0.9202\n",
      "  Learning Rate (group0): 9.78e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 1 - Epoch 6/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:38<00:00,  3.76s/it, loss=0.0204, acc=96.98%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.70s/it, loss=0.0495, acc=90.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0204, Acc: 96.98%, F1: 0.9699\n",
      "  Val   - Loss: 0.0495, Acc: 90.76%, F1: 0.9092\n",
      "  Learning Rate (group0): 9.68e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 1 - Epoch 7/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:39<00:00,  3.77s/it, loss=0.0229, acc=96.56%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0196, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0229, Acc: 96.56%, F1: 0.9657\n",
      "  Val   - Loss: 0.0196, Acc: 97.48%, F1: 0.9749\n",
      "  Learning Rate (group0): 9.57e-06\n",
      "  üíæ Best model saved! (Val Acc: 97.48%)\n",
      "  ‚úì New best score: 97.4790\n",
      "\n",
      "Fold 1 - Epoch 8/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:38<00:00,  3.76s/it, loss=0.0304, acc=96.49%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0260, acc=97.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0304, Acc: 96.49%, F1: 0.9651\n",
      "  Val   - Loss: 0.0260, Acc: 97.76%, F1: 0.9776\n",
      "  Learning Rate (group0): 9.44e-06\n",
      "  üíæ Best model saved! (Val Acc: 97.76%)\n",
      "  ‚úì New best score: 97.7591\n",
      "\n",
      "Fold 1 - Epoch 9/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:27<00:00,  3.64s/it, loss=0.0210, acc=96.91%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.63s/it, loss=0.0550, acc=95.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0210, Acc: 96.91%, F1: 0.9693\n",
      "  Val   - Loss: 0.0550, Acc: 95.52%, F1: 0.9546\n",
      "  Learning Rate (group0): 9.30e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 10/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:46<00:00,  3.85s/it, loss=0.0081, acc=99.09%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0216, acc=98.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0081, Acc: 99.09%, F1: 0.9909\n",
      "  Val   - Loss: 0.0216, Acc: 98.04%, F1: 0.9803\n",
      "  Learning Rate (group0): 9.14e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.04%)\n",
      "  ‚úì New best score: 98.0392\n",
      "\n",
      "Fold 1 - Epoch 11/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:41<00:00,  3.80s/it, loss=0.0169, acc=97.96%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.63s/it, loss=0.0297, acc=96.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0169, Acc: 97.96%, F1: 0.9797\n",
      "  Val   - Loss: 0.0297, Acc: 96.36%, F1: 0.9639\n",
      "  Learning Rate (group0): 8.97e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 12/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:38<00:00,  3.76s/it, loss=0.0105, acc=98.53%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0176, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0105, Acc: 98.53%, F1: 0.9853\n",
      "  Val   - Loss: 0.0176, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 8.78e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.32%)\n",
      "  ‚úì New best score: 98.3193\n",
      "\n",
      "Fold 1 - Epoch 13/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:33<00:00,  3.70s/it, loss=0.0046, acc=99.37%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.63s/it, loss=0.0194, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0046, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.0194, Acc: 97.48%, F1: 0.9748\n",
      "  Learning Rate (group0): 8.58e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 14/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:27<00:00,  3.64s/it, loss=0.0111, acc=98.81%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.57s/it, loss=0.0152, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0111, Acc: 98.81%, F1: 0.9881\n",
      "  Val   - Loss: 0.0152, Acc: 97.48%, F1: 0.9749\n",
      "  Learning Rate (group0): 8.37e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 1 - Epoch 15/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:03<00:00,  3.37s/it, loss=0.0095, acc=98.74%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0159, acc=97.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0095, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0159, Acc: 97.76%, F1: 0.9776\n",
      "  Learning Rate (group0): 8.15e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 1 - Epoch 16/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:50<00:00,  3.90s/it, loss=0.0037, acc=99.23%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0092, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0037, Acc: 99.23%, F1: 0.9923\n",
      "  Val   - Loss: 0.0092, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 7.91e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.60%)\n",
      "  ‚úì New best score: 98.5994\n",
      "\n",
      "Fold 1 - Epoch 17/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:03<00:00,  4.04s/it, loss=0.0015, acc=99.72%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.61s/it, loss=0.0130, acc=98.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0015, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0130, Acc: 98.04%, F1: 0.9805\n",
      "  Learning Rate (group0): 7.67e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 1 - Epoch 18/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:20<00:00,  4.23s/it, loss=0.0142, acc=98.46%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.84s/it, loss=0.0184, acc=95.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0142, Acc: 98.46%, F1: 0.9846\n",
      "  Val   - Loss: 0.0184, Acc: 95.80%, F1: 0.9583\n",
      "  Learning Rate (group0): 7.42e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 1 - Epoch 19/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:48<00:00,  4.54s/it, loss=0.0046, acc=99.16%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.78s/it, loss=0.0246, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0046, Acc: 99.16%, F1: 0.9916\n",
      "  Val   - Loss: 0.0246, Acc: 97.48%, F1: 0.9748\n",
      "  Learning Rate (group0): 7.16e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 1 - Epoch 20/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:03<00:00,  4.04s/it, loss=0.0111, acc=98.67%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.56s/it, loss=0.0163, acc=96.64%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0111, Acc: 98.67%, F1: 0.9867\n",
      "  Val   - Loss: 0.0163, Acc: 96.64%, F1: 0.9666\n",
      "  Learning Rate (group0): 6.89e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 1 - Epoch 21/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:42<00:00,  3.81s/it, loss=0.0026, acc=99.51%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.57s/it, loss=0.0131, acc=98.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0026, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0131, Acc: 98.04%, F1: 0.9804\n",
      "  Learning Rate (group0): 6.62e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 1 - Epoch 22/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:40<00:00,  3.78s/it, loss=0.0080, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.57s/it, loss=0.0485, acc=97.20%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0080, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0485, Acc: 97.20%, F1: 0.9718\n",
      "  Learning Rate (group0): 6.34e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 1 - Epoch 23/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:01<00:00,  4.01s/it, loss=0.0399, acc=96.28%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0200, acc=96.92%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0399, Acc: 96.28%, F1: 0.9628\n",
      "  Val   - Loss: 0.0200, Acc: 96.92%, F1: 0.9694\n",
      "  Learning Rate (group0): 6.06e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 1 - Epoch 24/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:49<00:00,  3.88s/it, loss=0.0064, acc=99.37%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.53s/it, loss=0.0221, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0064, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.0221, Acc: 97.48%, F1: 0.9749\n",
      "  Learning Rate (group0): 5.78e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 1 - Epoch 25/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:59<00:00,  3.99s/it, loss=0.0026, acc=99.58%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:43<00:00,  1.88s/it, loss=0.0187, acc=97.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0026, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.0187, Acc: 97.76%, F1: 0.9777\n",
      "  Learning Rate (group0): 5.50e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 1 - Epoch 26/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:54<00:00,  3.94s/it, loss=0.0027, acc=99.58%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.54s/it, loss=0.0145, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0027, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.0145, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 5.22e-06\n",
      "  No improvement. Patience: 10/10\n",
      "\n",
      "‚ö†Ô∏è Early stopping triggered!\n",
      "   Best score: 98.5994 at epoch 15\n",
      "\n",
      "‚ö†Ô∏è Early stopping at epoch 26\n",
      "\n",
      "üìä EVALUATING FOLD 1\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.56s/it, loss=0.0092, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Fold 1 Validation Results:\n",
      "  Accuracy:         98.60%\n",
      "  Precision:        0.9862\n",
      "  Recall:           0.9860\n",
      "  F1 Score:         0.9860\n",
      "  Sensitivity (Normal):   0.9695\n",
      "  Sensitivity (Abnormal): 0.9956\n",
      "  Specificity (Normal):   0.9922\n",
      "  Specificity (Abnormal): 0.9825\n",
      "  Avg Sensitivity:  0.9825\n",
      "  Avg Specificity:  0.9874\n",
      "‚úì Confusion matrix saved\n",
      "\n",
      "üìä Creating enhanced visualizations for Fold 1...\n",
      "  ‚úì Training curves saved\n",
      "  ‚úì Detailed confusion matrix saved\n",
      "  ‚úì Metrics summary saved\n",
      "\n",
      "======================================================================\n",
      "FOLD 2/5\n",
      "======================================================================\n",
      "\n",
      "üìä Fold 2 split:\n",
      "  Train:      1425 (80.0% of k-fold data)\n",
      "  Validation: 357 (20.0% of k-fold data)\n",
      "\n",
      "ü§ñ Creating model for Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2 - Epoch 1/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:40<00:00,  3.78s/it, loss=0.0975, acc=84.49%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.52s/it, loss=0.0555, acc=94.12%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0975, Acc: 84.49%, F1: 0.8464\n",
      "  Val   - Loss: 0.0555, Acc: 94.12%, F1: 0.9405\n",
      "  Learning Rate (group0): 9.99e-06\n",
      "  üíæ Best model saved! (Val Acc: 94.12%)\n",
      "  ‚úì Initial best score: 94.1176\n",
      "\n",
      "Fold 2 - Epoch 2/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:21<00:00,  4.24s/it, loss=0.0583, acc=91.16%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.80s/it, loss=0.1422, acc=87.96%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0583, Acc: 91.16%, F1: 0.9122\n",
      "  Val   - Loss: 0.1422, Acc: 87.96%, F1: 0.8730\n",
      "  Learning Rate (group0): 9.96e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 2 - Epoch 3/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:26<00:00,  4.29s/it, loss=0.0434, acc=94.04%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.74s/it, loss=0.0467, acc=95.24%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0434, Acc: 94.04%, F1: 0.9407\n",
      "  Val   - Loss: 0.0467, Acc: 95.24%, F1: 0.9515\n",
      "  Learning Rate (group0): 9.92e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.24%)\n",
      "  ‚úì New best score: 95.2381\n",
      "\n",
      "Fold 2 - Epoch 4/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:21<00:00,  4.24s/it, loss=0.0224, acc=97.12%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.75s/it, loss=0.0288, acc=95.52%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0224, Acc: 97.12%, F1: 0.9713\n",
      "  Val   - Loss: 0.0288, Acc: 95.52%, F1: 0.9556\n",
      "  Learning Rate (group0): 9.86e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.52%)\n",
      "  ‚úì New best score: 95.5182\n",
      "\n",
      "Fold 2 - Epoch 5/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:26<00:00,  4.29s/it, loss=0.0397, acc=94.60%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.82s/it, loss=0.0405, acc=92.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0397, Acc: 94.60%, F1: 0.9461\n",
      "  Val   - Loss: 0.0405, Acc: 92.44%, F1: 0.9256\n",
      "  Learning Rate (group0): 9.78e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 2 - Epoch 6/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:13<00:00,  4.15s/it, loss=0.0208, acc=97.05%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.74s/it, loss=0.0503, acc=90.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0208, Acc: 97.05%, F1: 0.9706\n",
      "  Val   - Loss: 0.0503, Acc: 90.76%, F1: 0.9093\n",
      "  Learning Rate (group0): 9.68e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 2 - Epoch 7/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.83s/it, loss=0.0210, acc=97.40%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:27<00:00,  1.19s/it, loss=0.0121, acc=98.04%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0210, Acc: 97.40%, F1: 0.9741\n",
      "  Val   - Loss: 0.0121, Acc: 98.04%, F1: 0.9804\n",
      "  Learning Rate (group0): 9.57e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.04%)\n",
      "  ‚úì New best score: 98.0392\n",
      "\n",
      "Fold 2 - Epoch 8/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:20<00:00,  3.56s/it, loss=0.0086, acc=98.53%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.12s/it, loss=0.0194, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0086, Acc: 98.53%, F1: 0.9853\n",
      "  Val   - Loss: 0.0194, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 9.44e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.32%)\n",
      "  ‚úì New best score: 98.3193\n",
      "\n",
      "Fold 2 - Epoch 9/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:40<00:00,  3.78s/it, loss=0.0208, acc=97.82%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.09s/it, loss=0.0182, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0208, Acc: 97.82%, F1: 0.9782\n",
      "  Val   - Loss: 0.0182, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 9.30e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 2 - Epoch 10/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:49<00:00,  3.88s/it, loss=0.0172, acc=97.47%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.12s/it, loss=0.0159, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0172, Acc: 97.47%, F1: 0.9748\n",
      "  Val   - Loss: 0.0159, Acc: 98.32%, F1: 0.9831\n",
      "  Learning Rate (group0): 9.14e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 2 - Epoch 11/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:49<00:00,  3.88s/it, loss=0.0125, acc=98.39%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.55s/it, loss=0.0139, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0125, Acc: 98.39%, F1: 0.9839\n",
      "  Val   - Loss: 0.0139, Acc: 97.48%, F1: 0.9747\n",
      "  Learning Rate (group0): 8.97e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 2 - Epoch 12/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:55<00:00,  3.95s/it, loss=0.0081, acc=98.95%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0112, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0081, Acc: 98.95%, F1: 0.9895\n",
      "  Val   - Loss: 0.0112, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 8.78e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 2 - Epoch 13/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:42<00:00,  3.81s/it, loss=0.0116, acc=98.60%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.2706, acc=85.71%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0116, Acc: 98.60%, F1: 0.9860\n",
      "  Val   - Loss: 0.2706, Acc: 85.71%, F1: 0.8477\n",
      "  Learning Rate (group0): 8.58e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 2 - Epoch 14/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.83s/it, loss=0.0133, acc=98.53%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.51s/it, loss=0.0077, acc=99.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0133, Acc: 98.53%, F1: 0.9853\n",
      "  Val   - Loss: 0.0077, Acc: 99.44%, F1: 0.9944\n",
      "  Learning Rate (group0): 8.37e-06\n",
      "  üíæ Best model saved! (Val Acc: 99.44%)\n",
      "  ‚úì New best score: 99.4398\n",
      "\n",
      "Fold 2 - Epoch 15/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:43<00:00,  3.81s/it, loss=0.0044, acc=99.37%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.56s/it, loss=0.0044, acc=99.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0044, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.0044, Acc: 99.72%, F1: 0.9972\n",
      "  Learning Rate (group0): 8.15e-06\n",
      "  üíæ Best model saved! (Val Acc: 99.72%)\n",
      "  ‚úì New best score: 99.7199\n",
      "\n",
      "Fold 2 - Epoch 16/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:57<00:00,  3.97s/it, loss=0.0081, acc=98.74%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.71s/it, loss=0.0149, acc=97.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0081, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0149, Acc: 97.48%, F1: 0.9750\n",
      "  Learning Rate (group0): 7.91e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 2 - Epoch 17/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:52<00:00,  3.91s/it, loss=0.0094, acc=98.88%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.54s/it, loss=0.0078, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0094, Acc: 98.88%, F1: 0.9888\n",
      "  Val   - Loss: 0.0078, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 7.67e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 2 - Epoch 18/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.82s/it, loss=0.0021, acc=99.79%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.53s/it, loss=0.0157, acc=97.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0021, Acc: 99.79%, F1: 0.9979\n",
      "  Val   - Loss: 0.0157, Acc: 97.76%, F1: 0.9776\n",
      "  Learning Rate (group0): 7.42e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 2 - Epoch 19/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.83s/it, loss=0.0047, acc=99.37%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.54s/it, loss=0.0090, acc=99.44%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0047, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.0090, Acc: 99.44%, F1: 0.9944\n",
      "  Learning Rate (group0): 7.16e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 2 - Epoch 20/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:44<00:00,  3.82s/it, loss=0.0036, acc=99.58%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.55s/it, loss=0.0044, acc=99.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0036, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.0044, Acc: 99.72%, F1: 0.9972\n",
      "  Learning Rate (group0): 6.89e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 2 - Epoch 21/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:42<00:00,  3.81s/it, loss=0.0061, acc=99.02%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.78s/it, loss=0.2773, acc=77.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0061, Acc: 99.02%, F1: 0.9902\n",
      "  Val   - Loss: 0.2773, Acc: 77.31%, F1: 0.7762\n",
      "  Learning Rate (group0): 6.62e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 2 - Epoch 22/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:59<00:00,  3.99s/it, loss=0.0123, acc=98.18%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.53s/it, loss=0.0067, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0123, Acc: 98.18%, F1: 0.9818\n",
      "  Val   - Loss: 0.0067, Acc: 98.88%, F1: 0.9888\n",
      "  Learning Rate (group0): 6.34e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 2 - Epoch 23/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:43<00:00,  3.82s/it, loss=0.0019, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.52s/it, loss=0.0038, acc=99.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0019, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0038, Acc: 99.72%, F1: 0.9972\n",
      "  Learning Rate (group0): 6.06e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 2 - Epoch 24/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:42<00:00,  3.81s/it, loss=0.0021, acc=99.58%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.59s/it, loss=0.0086, acc=97.76%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0021, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.0086, Acc: 97.76%, F1: 0.9777\n",
      "  Learning Rate (group0): 5.78e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 2 - Epoch 25/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:00<00:00,  4.01s/it, loss=0.0064, acc=99.23%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:46<00:00,  2.03s/it, loss=0.0183, acc=98.32%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0064, Acc: 99.23%, F1: 0.9923\n",
      "  Val   - Loss: 0.0183, Acc: 98.32%, F1: 0.9832\n",
      "  Learning Rate (group0): 5.50e-06\n",
      "  No improvement. Patience: 10/10\n",
      "\n",
      "‚ö†Ô∏è Early stopping triggered!\n",
      "   Best score: 99.7199 at epoch 14\n",
      "\n",
      "‚ö†Ô∏è Early stopping at epoch 25\n",
      "\n",
      "üìä EVALUATING FOLD 2\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:44<00:00,  1.93s/it, loss=0.0044, acc=99.72%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Fold 2 Validation Results:\n",
      "  Accuracy:         99.72%\n",
      "  Precision:        0.9972\n",
      "  Recall:           0.9972\n",
      "  F1 Score:         0.9972\n",
      "  Sensitivity (Normal):   1.0000\n",
      "  Sensitivity (Abnormal): 0.9957\n",
      "  Specificity (Normal):   0.9922\n",
      "  Specificity (Abnormal): 1.0000\n",
      "  Avg Sensitivity:  0.9978\n",
      "  Avg Specificity:  0.9961\n",
      "‚úì Confusion matrix saved\n",
      "\n",
      "======================================================================\n",
      "FOLD 3/5\n",
      "======================================================================\n",
      "\n",
      "üìä Fold 3 split:\n",
      "  Train:      1426 (80.0% of k-fold data)\n",
      "  Validation: 356 (20.0% of k-fold data)\n",
      "\n",
      "ü§ñ Creating model for Fold 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 - Epoch 1/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:24<00:00,  4.27s/it, loss=0.1094, acc=80.43%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.53s/it, loss=0.0661, acc=91.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.1094, Acc: 80.43%, F1: 0.8072\n",
      "  Val   - Loss: 0.0661, Acc: 91.85%, F1: 0.9171\n",
      "  Learning Rate (group0): 9.99e-06\n",
      "  üíæ Best model saved! (Val Acc: 91.85%)\n",
      "  ‚úì Initial best score: 91.8539\n",
      "\n",
      "Fold 3 - Epoch 2/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:29<00:00,  4.33s/it, loss=0.0538, acc=92.50%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.64s/it, loss=0.0729, acc=91.29%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0538, Acc: 92.50%, F1: 0.9253\n",
      "  Val   - Loss: 0.0729, Acc: 91.29%, F1: 0.9133\n",
      "  Learning Rate (group0): 9.96e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 3 - Epoch 3/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:25<00:00,  4.28s/it, loss=0.0517, acc=93.41%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.83s/it, loss=0.0334, acc=95.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0517, Acc: 93.41%, F1: 0.9343\n",
      "  Val   - Loss: 0.0334, Acc: 95.22%, F1: 0.9525\n",
      "  Learning Rate (group0): 9.92e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.22%)\n",
      "  ‚úì New best score: 95.2247\n",
      "\n",
      "Fold 3 - Epoch 4/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:23<00:00,  4.26s/it, loss=0.0328, acc=96.35%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.57s/it, loss=0.0409, acc=93.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0328, Acc: 96.35%, F1: 0.9637\n",
      "  Val   - Loss: 0.0409, Acc: 93.54%, F1: 0.9361\n",
      "  Learning Rate (group0): 9.86e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 3 - Epoch 5/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:49<00:00,  3.88s/it, loss=0.0270, acc=96.42%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:50<00:00,  2.18s/it, loss=0.0316, acc=94.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0270, Acc: 96.42%, F1: 0.9643\n",
      "  Val   - Loss: 0.0316, Acc: 94.94%, F1: 0.9495\n",
      "  Learning Rate (group0): 9.78e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 3 - Epoch 6/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:57<00:00,  4.64s/it, loss=0.0218, acc=97.34%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:43<00:00,  1.89s/it, loss=0.1592, acc=88.48%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0218, Acc: 97.34%, F1: 0.9734\n",
      "  Val   - Loss: 0.1592, Acc: 88.48%, F1: 0.8790\n",
      "  Learning Rate (group0): 9.68e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 3 - Epoch 7/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:46<00:00,  4.52s/it, loss=0.0211, acc=96.70%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:52<00:00,  2.30s/it, loss=0.0321, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0211, Acc: 96.70%, F1: 0.9671\n",
      "  Val   - Loss: 0.0321, Acc: 95.79%, F1: 0.9580\n",
      "  Learning Rate (group0): 9.57e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.79%)\n",
      "  ‚úì New best score: 95.7865\n",
      "\n",
      "Fold 3 - Epoch 8/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:57<00:00,  4.64s/it, loss=0.0106, acc=98.74%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.85s/it, loss=0.0134, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0106, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0134, Acc: 98.60%, F1: 0.9859\n",
      "  Learning Rate (group0): 9.44e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.60%)\n",
      "  ‚úì New best score: 98.5955\n",
      "\n",
      "Fold 3 - Epoch 9/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:33<00:00,  3.71s/it, loss=0.0145, acc=98.11%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.74s/it, loss=0.0205, acc=96.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0145, Acc: 98.11%, F1: 0.9811\n",
      "  Val   - Loss: 0.0205, Acc: 96.63%, F1: 0.9662\n",
      "  Learning Rate (group0): 9.30e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 3 - Epoch 10/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:08<00:00,  4.10s/it, loss=0.0115, acc=98.32%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.76s/it, loss=0.0228, acc=97.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0115, Acc: 98.32%, F1: 0.9832\n",
      "  Val   - Loss: 0.0228, Acc: 97.75%, F1: 0.9776\n",
      "  Learning Rate (group0): 9.14e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 3 - Epoch 11/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:57<00:00,  3.97s/it, loss=0.0191, acc=97.27%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.78s/it, loss=0.0311, acc=96.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0191, Acc: 97.27%, F1: 0.9727\n",
      "  Val   - Loss: 0.0311, Acc: 96.35%, F1: 0.9632\n",
      "  Learning Rate (group0): 8.97e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 3 - Epoch 12/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:12<00:00,  4.14s/it, loss=0.0049, acc=99.37%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:45<00:00,  1.98s/it, loss=0.1790, acc=90.17%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0049, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.1790, Acc: 90.17%, F1: 0.8974\n",
      "  Learning Rate (group0): 8.78e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 3 - Epoch 13/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:16<00:00,  4.18s/it, loss=0.0191, acc=97.27%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:32<00:00,  1.41s/it, loss=0.0171, acc=97.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0191, Acc: 97.27%, F1: 0.9727\n",
      "  Val   - Loss: 0.0171, Acc: 97.75%, F1: 0.9777\n",
      "  Learning Rate (group0): 8.58e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 3 - Epoch 14/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:17<00:00,  3.53s/it, loss=0.0069, acc=98.53%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.77s/it, loss=0.0160, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0069, Acc: 98.53%, F1: 0.9853\n",
      "  Val   - Loss: 0.0160, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 8.37e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 3 - Epoch 15/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:45<00:00,  3.84s/it, loss=0.0178, acc=98.46%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.61s/it, loss=0.0199, acc=96.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0178, Acc: 98.46%, F1: 0.9846\n",
      "  Val   - Loss: 0.0199, Acc: 96.35%, F1: 0.9634\n",
      "  Learning Rate (group0): 8.15e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 3 - Epoch 16/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:38<00:00,  3.76s/it, loss=0.0236, acc=96.84%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.59s/it, loss=0.0303, acc=96.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0236, Acc: 96.84%, F1: 0.9686\n",
      "  Val   - Loss: 0.0303, Acc: 96.63%, F1: 0.9665\n",
      "  Learning Rate (group0): 7.91e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 3 - Epoch 17/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:03<00:00,  4.04s/it, loss=0.0056, acc=99.30%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0179, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0056, Acc: 99.30%, F1: 0.9930\n",
      "  Val   - Loss: 0.0179, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 7.67e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 3 - Epoch 18/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:15<00:00,  4.18s/it, loss=0.0034, acc=99.44%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:44<00:00,  1.92s/it, loss=0.0100, acc=98.88%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0034, Acc: 99.44%, F1: 0.9944\n",
      "  Val   - Loss: 0.0100, Acc: 98.88%, F1: 0.9888\n",
      "  Learning Rate (group0): 7.42e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.88%)\n",
      "  ‚úì New best score: 98.8764\n",
      "\n",
      "Fold 3 - Epoch 19/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:14<00:00,  4.16s/it, loss=0.0054, acc=99.51%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0137, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0054, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0137, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 7.16e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 3 - Epoch 20/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:55<00:00,  3.94s/it, loss=0.0040, acc=99.58%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.1078, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0040, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.1078, Acc: 95.79%, F1: 0.9573\n",
      "  Learning Rate (group0): 6.89e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 3 - Epoch 21/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:33<00:00,  4.38s/it, loss=0.0056, acc=99.16%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0119, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0056, Acc: 99.16%, F1: 0.9916\n",
      "  Val   - Loss: 0.0119, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 6.62e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 3 - Epoch 22/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:47<00:00,  3.87s/it, loss=0.0011, acc=99.86%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:28<00:00,  1.23s/it, loss=0.0103, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0011, Acc: 99.86%, F1: 0.9986\n",
      "  Val   - Loss: 0.0103, Acc: 98.88%, F1: 0.9888\n",
      "  Learning Rate (group0): 6.34e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 3 - Epoch 23/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:46<00:00,  3.85s/it, loss=0.0060, acc=98.95%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0139, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0060, Acc: 98.95%, F1: 0.9895\n",
      "  Val   - Loss: 0.0139, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 6.06e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 3 - Epoch 24/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:47<00:00,  3.86s/it, loss=0.0026, acc=99.58%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.50s/it, loss=0.0093, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0026, Acc: 99.58%, F1: 0.9958\n",
      "  Val   - Loss: 0.0093, Acc: 98.60%, F1: 0.9859\n",
      "  Learning Rate (group0): 5.78e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 3 - Epoch 25/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:36<00:00,  3.74s/it, loss=0.0011, acc=99.79%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:50<00:00,  2.19s/it, loss=0.0188, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0011, Acc: 99.79%, F1: 0.9979\n",
      "  Val   - Loss: 0.0188, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 5.50e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 3 - Epoch 26/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:15<00:00,  4.17s/it, loss=0.0033, acc=99.65%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.70s/it, loss=0.0127, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0033, Acc: 99.65%, F1: 0.9965\n",
      "  Val   - Loss: 0.0127, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 5.22e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 3 - Epoch 27/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:51<00:00,  4.57s/it, loss=0.0025, acc=99.51%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.71s/it, loss=0.0153, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0025, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0153, Acc: 98.88%, F1: 0.9887\n",
      "  Learning Rate (group0): 4.94e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 3 - Epoch 28/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [07:13<00:00,  4.81s/it, loss=0.0016, acc=99.65%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:46<00:00,  2.01s/it, loss=0.0114, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0016, Acc: 99.65%, F1: 0.9965\n",
      "  Val   - Loss: 0.0114, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 4.66e-06\n",
      "  No improvement. Patience: 10/10\n",
      "\n",
      "‚ö†Ô∏è Early stopping triggered!\n",
      "   Best score: 98.8764 at epoch 17\n",
      "\n",
      "‚ö†Ô∏è Early stopping at epoch 28\n",
      "\n",
      "üìä EVALUATING FOLD 3\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0100, acc=98.88%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Fold 3 Validation Results:\n",
      "  Accuracy:         98.88%\n",
      "  Precision:        0.9889\n",
      "  Recall:           0.9888\n",
      "  F1 Score:         0.9888\n",
      "  Sensitivity (Normal):   0.9769\n",
      "  Sensitivity (Abnormal): 0.9956\n",
      "  Specificity (Normal):   0.9922\n",
      "  Specificity (Abnormal): 0.9868\n",
      "  Avg Sensitivity:  0.9862\n",
      "  Avg Specificity:  0.9895\n",
      "‚úì Confusion matrix saved\n",
      "\n",
      "======================================================================\n",
      "FOLD 4/5\n",
      "======================================================================\n",
      "\n",
      "üìä Fold 4 split:\n",
      "  Train:      1426 (80.0% of k-fold data)\n",
      "  Validation: 356 (20.0% of k-fold data)\n",
      "\n",
      "ü§ñ Creating model for Fold 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 - Epoch 1/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:01<00:00,  4.02s/it, loss=0.1034, acc=82.82%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.49s/it, loss=0.0595, acc=91.85%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.1034, Acc: 82.82%, F1: 0.8301\n",
      "  Val   - Loss: 0.0595, Acc: 91.85%, F1: 0.9177\n",
      "  Learning Rate (group0): 9.99e-06\n",
      "  üíæ Best model saved! (Val Acc: 91.85%)\n",
      "  ‚úì Initial best score: 91.8539\n",
      "\n",
      "Fold 4 - Epoch 2/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:15<00:00,  4.18s/it, loss=0.0546, acc=92.15%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:44<00:00,  1.95s/it, loss=0.0412, acc=92.42%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0546, Acc: 92.15%, F1: 0.9218\n",
      "  Val   - Loss: 0.0412, Acc: 92.42%, F1: 0.9252\n",
      "  Learning Rate (group0): 9.96e-06\n",
      "  üíæ Best model saved! (Val Acc: 92.42%)\n",
      "  ‚úì New best score: 92.4157\n",
      "\n",
      "Fold 4 - Epoch 3/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:26<00:00,  4.30s/it, loss=0.0382, acc=94.95%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:39<00:00,  1.73s/it, loss=0.0311, acc=94.94%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0382, Acc: 94.95%, F1: 0.9496\n",
      "  Val   - Loss: 0.0311, Acc: 94.94%, F1: 0.9499\n",
      "  Learning Rate (group0): 9.92e-06\n",
      "  üíæ Best model saved! (Val Acc: 94.94%)\n",
      "  ‚úì New best score: 94.9438\n",
      "\n",
      "Fold 4 - Epoch 4/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:27<00:00,  4.31s/it, loss=0.0368, acc=94.67%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0327, acc=94.66%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0368, Acc: 94.67%, F1: 0.9470\n",
      "  Val   - Loss: 0.0327, Acc: 94.66%, F1: 0.9473\n",
      "  Learning Rate (group0): 9.86e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 5/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:43<00:00,  3.82s/it, loss=0.0312, acc=96.14%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:33<00:00,  1.47s/it, loss=0.0264, acc=96.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0312, Acc: 96.14%, F1: 0.9615\n",
      "  Val   - Loss: 0.0264, Acc: 96.63%, F1: 0.9662\n",
      "  Learning Rate (group0): 9.78e-06\n",
      "  üíæ Best model saved! (Val Acc: 96.63%)\n",
      "  ‚úì New best score: 96.6292\n",
      "\n",
      "Fold 4 - Epoch 6/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:08<00:00,  4.09s/it, loss=0.0197, acc=97.27%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.56s/it, loss=0.0298, acc=94.38%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0197, Acc: 97.27%, F1: 0.9727\n",
      "  Val   - Loss: 0.0298, Acc: 94.38%, F1: 0.9446\n",
      "  Learning Rate (group0): 9.68e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 7/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:26<00:00,  4.29s/it, loss=0.0168, acc=97.69%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:27<00:00,  1.19s/it, loss=0.0251, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0168, Acc: 97.69%, F1: 0.9769\n",
      "  Val   - Loss: 0.0251, Acc: 95.79%, F1: 0.9582\n",
      "  Learning Rate (group0): 9.57e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 4 - Epoch 8/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:04<00:00,  3.39s/it, loss=0.0151, acc=97.97%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:38<00:00,  1.68s/it, loss=0.0155, acc=96.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0151, Acc: 97.97%, F1: 0.9797\n",
      "  Val   - Loss: 0.0155, Acc: 96.63%, F1: 0.9665\n",
      "  Learning Rate (group0): 9.44e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 4 - Epoch 9/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:09<00:00,  4.10s/it, loss=0.0078, acc=99.02%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.51s/it, loss=0.0180, acc=97.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0078, Acc: 99.02%, F1: 0.9902\n",
      "  Val   - Loss: 0.0180, Acc: 97.19%, F1: 0.9721\n",
      "  Learning Rate (group0): 9.30e-06\n",
      "  üíæ Best model saved! (Val Acc: 97.19%)\n",
      "  ‚úì New best score: 97.1910\n",
      "\n",
      "Fold 4 - Epoch 10/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:23<00:00,  4.26s/it, loss=0.0116, acc=98.25%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.83s/it, loss=0.0203, acc=96.91%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0116, Acc: 98.25%, F1: 0.9825\n",
      "  Val   - Loss: 0.0203, Acc: 96.91%, F1: 0.9693\n",
      "  Learning Rate (group0): 9.14e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 11/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:25<00:00,  4.29s/it, loss=0.0109, acc=98.32%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.82s/it, loss=0.1993, acc=76.69%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0109, Acc: 98.32%, F1: 0.9832\n",
      "  Val   - Loss: 0.1993, Acc: 76.69%, F1: 0.7695\n",
      "  Learning Rate (group0): 8.97e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 4 - Epoch 12/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:16<00:00,  4.19s/it, loss=0.0188, acc=97.34%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.79s/it, loss=0.0305, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0188, Acc: 97.34%, F1: 0.9734\n",
      "  Val   - Loss: 0.0305, Acc: 95.79%, F1: 0.9582\n",
      "  Learning Rate (group0): 8.78e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 4 - Epoch 13/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:17<00:00,  4.19s/it, loss=0.0107, acc=98.60%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.77s/it, loss=0.0409, acc=97.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0107, Acc: 98.60%, F1: 0.9860\n",
      "  Val   - Loss: 0.0409, Acc: 97.47%, F1: 0.9747\n",
      "  Learning Rate (group0): 8.58e-06\n",
      "  üíæ Best model saved! (Val Acc: 97.47%)\n",
      "  ‚úì New best score: 97.4719\n",
      "\n",
      "Fold 4 - Epoch 14/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:24<00:00,  4.27s/it, loss=0.0081, acc=98.81%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.84s/it, loss=0.0551, acc=93.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0081, Acc: 98.81%, F1: 0.9881\n",
      "  Val   - Loss: 0.0551, Acc: 93.54%, F1: 0.9362\n",
      "  Learning Rate (group0): 8.37e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 15/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:07<00:00,  4.09s/it, loss=0.0133, acc=97.97%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.82s/it, loss=0.0380, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0133, Acc: 97.97%, F1: 0.9797\n",
      "  Val   - Loss: 0.0380, Acc: 95.79%, F1: 0.9582\n",
      "  Learning Rate (group0): 8.15e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 4 - Epoch 16/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:15<00:00,  4.17s/it, loss=0.0061, acc=99.09%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.77s/it, loss=0.0281, acc=96.35%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0061, Acc: 99.09%, F1: 0.9909\n",
      "  Val   - Loss: 0.0281, Acc: 96.35%, F1: 0.9637\n",
      "  Learning Rate (group0): 7.91e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 4 - Epoch 17/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:51<00:00,  3.90s/it, loss=0.0036, acc=99.65%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.61s/it, loss=0.0222, acc=96.63%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0036, Acc: 99.65%, F1: 0.9965\n",
      "  Val   - Loss: 0.0222, Acc: 96.63%, F1: 0.9665\n",
      "  Learning Rate (group0): 7.67e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 4 - Epoch 18/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:36<00:00,  3.74s/it, loss=0.0023, acc=99.79%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:37<00:00,  1.62s/it, loss=0.0247, acc=97.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0023, Acc: 99.79%, F1: 0.9979\n",
      "  Val   - Loss: 0.0247, Acc: 97.19%, F1: 0.9720\n",
      "  Learning Rate (group0): 7.42e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 4 - Epoch 19/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:48<00:00,  3.87s/it, loss=0.0028, acc=99.79%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.57s/it, loss=0.0279, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0028, Acc: 99.79%, F1: 0.9979\n",
      "  Val   - Loss: 0.0279, Acc: 98.03%, F1: 0.9804\n",
      "  Learning Rate (group0): 7.16e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.03%)\n",
      "  ‚úì New best score: 98.0337\n",
      "\n",
      "Fold 4 - Epoch 20/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:41<00:00,  3.79s/it, loss=0.0138, acc=98.25%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.59s/it, loss=0.0229, acc=95.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0138, Acc: 98.25%, F1: 0.9825\n",
      "  Val   - Loss: 0.0229, Acc: 95.22%, F1: 0.9528\n",
      "  Learning Rate (group0): 6.89e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 21/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:21<00:00,  3.57s/it, loss=0.0069, acc=99.23%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.78s/it, loss=0.0095, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0069, Acc: 99.23%, F1: 0.9923\n",
      "  Val   - Loss: 0.0095, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 6.62e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.31%)\n",
      "  ‚úì New best score: 98.3146\n",
      "\n",
      "Fold 4 - Epoch 22/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:01<00:00,  4.01s/it, loss=0.0082, acc=98.81%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.82s/it, loss=0.0115, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0082, Acc: 98.81%, F1: 0.9881\n",
      "  Val   - Loss: 0.0115, Acc: 98.88%, F1: 0.9888\n",
      "  Learning Rate (group0): 6.34e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.88%)\n",
      "  ‚úì New best score: 98.8764\n",
      "\n",
      "Fold 4 - Epoch 23/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:33<00:00,  4.37s/it, loss=0.0049, acc=99.51%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.83s/it, loss=0.0287, acc=97.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0049, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0287, Acc: 97.75%, F1: 0.9774\n",
      "  Learning Rate (group0): 6.06e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 4 - Epoch 24/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:25<00:00,  4.28s/it, loss=0.0019, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:42<00:00,  1.85s/it, loss=0.0125, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0019, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0125, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 5.78e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 4 - Epoch 25/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:15<00:00,  4.18s/it, loss=0.0039, acc=99.44%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:41<00:00,  1.81s/it, loss=0.0202, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0039, Acc: 99.44%, F1: 0.9944\n",
      "  Val   - Loss: 0.0202, Acc: 98.03%, F1: 0.9804\n",
      "  Learning Rate (group0): 5.50e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 4 - Epoch 26/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:45<00:00,  3.84s/it, loss=0.0090, acc=98.74%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.60s/it, loss=0.0300, acc=95.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0090, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0300, Acc: 95.22%, F1: 0.9528\n",
      "  Learning Rate (group0): 5.22e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 4 - Epoch 27/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:28<00:00,  3.65s/it, loss=0.0064, acc=99.23%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:30<00:00,  1.33s/it, loss=0.0123, acc=97.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0064, Acc: 99.23%, F1: 0.9923\n",
      "  Val   - Loss: 0.0123, Acc: 97.75%, F1: 0.9776\n",
      "  Learning Rate (group0): 4.94e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 4 - Epoch 28/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:40<00:00,  3.79s/it, loss=0.0087, acc=99.16%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.52s/it, loss=0.0107, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0087, Acc: 99.16%, F1: 0.9916\n",
      "  Val   - Loss: 0.0107, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 4.66e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 4 - Epoch 29/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:33<00:00,  3.70s/it, loss=0.0010, acc=99.93%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.51s/it, loss=0.0123, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0010, Acc: 99.93%, F1: 0.9993\n",
      "  Val   - Loss: 0.0123, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 4.38e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 4 - Epoch 30/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:13<00:00,  4.15s/it, loss=0.0007, acc=100.00%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:34<00:00,  1.49s/it, loss=0.0108, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0007, Acc: 100.00%, F1: 1.0000\n",
      "  Val   - Loss: 0.0108, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 4.11e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 4 - Epoch 31/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:34<00:00,  3.71s/it, loss=0.0011, acc=99.86%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:33<00:00,  1.45s/it, loss=0.0146, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0011, Acc: 99.86%, F1: 0.9986\n",
      "  Val   - Loss: 0.0146, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 3.84e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 4 - Epoch 32/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [05:46<00:00,  3.85s/it, loss=0.0006, acc=99.93%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:40<00:00,  1.74s/it, loss=0.0188, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0006, Acc: 99.93%, F1: 0.9993\n",
      "  Val   - Loss: 0.0188, Acc: 98.31%, F1: 0.9832\n",
      "  Learning Rate (group0): 3.58e-06\n",
      "  No improvement. Patience: 10/10\n",
      "\n",
      "‚ö†Ô∏è Early stopping triggered!\n",
      "   Best score: 98.8764 at epoch 21\n",
      "\n",
      "‚ö†Ô∏è Early stopping at epoch 32\n",
      "\n",
      "üìä EVALUATING FOLD 4\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:36<00:00,  1.58s/it, loss=0.0115, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Fold 4 Validation Results:\n",
      "  Accuracy:         98.88%\n",
      "  Precision:        0.9889\n",
      "  Recall:           0.9888\n",
      "  F1 Score:         0.9888\n",
      "  Sensitivity (Normal):   0.9769\n",
      "  Sensitivity (Abnormal): 0.9956\n",
      "  Specificity (Normal):   0.9922\n",
      "  Specificity (Abnormal): 0.9868\n",
      "  Avg Sensitivity:  0.9862\n",
      "  Avg Specificity:  0.9895\n",
      "‚úì Confusion matrix saved\n",
      "\n",
      "======================================================================\n",
      "FOLD 5/5\n",
      "======================================================================\n",
      "\n",
      "üìä Fold 5 split:\n",
      "  Train:      1426 (80.0% of k-fold data)\n",
      "  Validation: 356 (20.0% of k-fold data)\n",
      "\n",
      "ü§ñ Creating model for Fold 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5 - Epoch 1/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [06:10<00:00,  4.12s/it, loss=0.0985, acc=83.52%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:35<00:00,  1.55s/it, loss=0.1259, acc=87.36%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0985, Acc: 83.52%, F1: 0.8369\n",
      "  Val   - Loss: 0.1259, Acc: 87.36%, F1: 0.8672\n",
      "  Learning Rate (group0): 9.99e-06\n",
      "  üíæ Best model saved! (Val Acc: 87.36%)\n",
      "  ‚úì Initial best score: 87.3596\n",
      "\n",
      "Fold 5 - Epoch 2/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:51<00:00,  3.24s/it, loss=0.0604, acc=91.51%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:27<00:00,  1.19s/it, loss=0.1301, acc=84.55%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0604, Acc: 91.51%, F1: 0.9156\n",
      "  Val   - Loss: 0.1301, Acc: 84.55%, F1: 0.8341\n",
      "  Learning Rate (group0): 9.96e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 3/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:24<00:00,  2.94s/it, loss=0.0461, acc=93.90%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0414, acc=93.54%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0461, Acc: 93.90%, F1: 0.9393\n",
      "  Val   - Loss: 0.0414, Acc: 93.54%, F1: 0.9358\n",
      "  Learning Rate (group0): 9.92e-06\n",
      "  üíæ Best model saved! (Val Acc: 93.54%)\n",
      "  ‚úì New best score: 93.5393\n",
      "\n",
      "Fold 5 - Epoch 4/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:31<00:00,  3.02s/it, loss=0.0258, acc=96.49%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.10s/it, loss=0.0946, acc=86.80%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0258, Acc: 96.49%, F1: 0.9650\n",
      "  Val   - Loss: 0.0946, Acc: 86.80%, F1: 0.8705\n",
      "  Learning Rate (group0): 9.86e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 5/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:38<00:00,  3.10s/it, loss=0.0318, acc=96.21%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:28<00:00,  1.23s/it, loss=0.0343, acc=95.22%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0318, Acc: 96.21%, F1: 0.9623\n",
      "  Val   - Loss: 0.0343, Acc: 95.22%, F1: 0.9524\n",
      "  Learning Rate (group0): 9.78e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.22%)\n",
      "  ‚úì New best score: 95.2247\n",
      "\n",
      "Fold 5 - Epoch 6/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:48<00:00,  3.20s/it, loss=0.0288, acc=96.35%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.11s/it, loss=0.0442, acc=95.79%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0288, Acc: 96.35%, F1: 0.9636\n",
      "  Val   - Loss: 0.0442, Acc: 95.79%, F1: 0.9572\n",
      "  Learning Rate (group0): 9.68e-06\n",
      "  üíæ Best model saved! (Val Acc: 95.79%)\n",
      "  ‚úì New best score: 95.7865\n",
      "\n",
      "Fold 5 - Epoch 7/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:27<00:00,  2.97s/it, loss=0.0211, acc=97.41%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0334, acc=97.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0211, Acc: 97.41%, F1: 0.9741\n",
      "  Val   - Loss: 0.0334, Acc: 97.47%, F1: 0.9746\n",
      "  Learning Rate (group0): 9.57e-06\n",
      "  üíæ Best model saved! (Val Acc: 97.47%)\n",
      "  ‚úì New best score: 97.4719\n",
      "\n",
      "Fold 5 - Epoch 8/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:28<00:00,  2.99s/it, loss=0.0160, acc=97.90%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0244, acc=97.19%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0160, Acc: 97.90%, F1: 0.9790\n",
      "  Val   - Loss: 0.0244, Acc: 97.19%, F1: 0.9718\n",
      "  Learning Rate (group0): 9.44e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 9/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:28<00:00,  2.98s/it, loss=0.0117, acc=98.74%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.08s/it, loss=0.0325, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0117, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0325, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 9.30e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.31%)\n",
      "  ‚úì New best score: 98.3146\n",
      "\n",
      "Fold 5 - Epoch 10/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:32<00:00,  3.02s/it, loss=0.0122, acc=98.25%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.08s/it, loss=0.0822, acc=93.82%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0122, Acc: 98.25%, F1: 0.9825\n",
      "  Val   - Loss: 0.0822, Acc: 93.82%, F1: 0.9370\n",
      "  Learning Rate (group0): 9.14e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 11/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:25<00:00,  2.95s/it, loss=0.0193, acc=97.41%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0225, acc=98.60%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0193, Acc: 97.41%, F1: 0.9741\n",
      "  Val   - Loss: 0.0225, Acc: 98.60%, F1: 0.9859\n",
      "  Learning Rate (group0): 8.97e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.60%)\n",
      "  ‚úì New best score: 98.5955\n",
      "\n",
      "Fold 5 - Epoch 12/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:24<00:00,  2.94s/it, loss=0.0106, acc=99.02%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0248, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0106, Acc: 99.02%, F1: 0.9902\n",
      "  Val   - Loss: 0.0248, Acc: 98.03%, F1: 0.9803\n",
      "  Learning Rate (group0): 8.78e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 13/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:38<00:00,  3.10s/it, loss=0.0091, acc=98.60%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:27<00:00,  1.20s/it, loss=0.0078, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0091, Acc: 98.60%, F1: 0.9860\n",
      "  Val   - Loss: 0.0078, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 8.58e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 5 - Epoch 14/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:33<00:00,  3.04s/it, loss=0.0101, acc=98.46%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.12s/it, loss=0.0242, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0101, Acc: 98.46%, F1: 0.9846\n",
      "  Val   - Loss: 0.0242, Acc: 98.03%, F1: 0.9802\n",
      "  Learning Rate (group0): 8.37e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 5 - Epoch 15/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:27<00:00,  2.97s/it, loss=0.0118, acc=98.60%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0106, acc=98.88%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0118, Acc: 98.60%, F1: 0.9860\n",
      "  Val   - Loss: 0.0106, Acc: 98.88%, F1: 0.9887\n",
      "  Learning Rate (group0): 8.15e-06\n",
      "  üíæ Best model saved! (Val Acc: 98.88%)\n",
      "  ‚úì New best score: 98.8764\n",
      "\n",
      "Fold 5 - Epoch 16/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:22<00:00,  2.92s/it, loss=0.0095, acc=99.02%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0292, acc=97.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0095, Acc: 99.02%, F1: 0.9902\n",
      "  Val   - Loss: 0.0292, Acc: 97.47%, F1: 0.9745\n",
      "  Learning Rate (group0): 7.91e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 17/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:33<00:00,  3.03s/it, loss=0.0086, acc=98.74%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:29<00:00,  1.26s/it, loss=0.0180, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0086, Acc: 98.74%, F1: 0.9874\n",
      "  Val   - Loss: 0.0180, Acc: 98.03%, F1: 0.9803\n",
      "  Learning Rate (group0): 7.67e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 5 - Epoch 18/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:42<00:00,  3.13s/it, loss=0.0052, acc=99.23%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0320, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0052, Acc: 99.23%, F1: 0.9923\n",
      "  Val   - Loss: 0.0320, Acc: 98.88%, F1: 0.9887\n",
      "  Learning Rate (group0): 7.42e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 5 - Epoch 19/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:23<00:00,  2.93s/it, loss=0.0038, acc=99.44%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0271, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0038, Acc: 99.44%, F1: 0.9944\n",
      "  Val   - Loss: 0.0271, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 7.16e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 5 - Epoch 20/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:29<00:00,  3.00s/it, loss=0.0073, acc=99.37%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0108, acc=99.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0073, Acc: 99.37%, F1: 0.9937\n",
      "  Val   - Loss: 0.0108, Acc: 99.16%, F1: 0.9916\n",
      "  Learning Rate (group0): 6.89e-06\n",
      "  üíæ Best model saved! (Val Acc: 99.16%)\n",
      "  ‚úì New best score: 99.1573\n",
      "\n",
      "Fold 5 - Epoch 21/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:24<00:00,  2.94s/it, loss=0.0052, acc=99.51%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0179, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0052, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0179, Acc: 98.60%, F1: 0.9859\n",
      "  Learning Rate (group0): 6.62e-06\n",
      "  No improvement. Patience: 1/10\n",
      "\n",
      "Fold 5 - Epoch 22/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:18<00:00,  2.87s/it, loss=0.0035, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.05s/it, loss=0.0158, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0035, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0158, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 6.34e-06\n",
      "  No improvement. Patience: 2/10\n",
      "\n",
      "Fold 5 - Epoch 23/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:22<00:00,  2.92s/it, loss=0.0028, acc=99.51%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.07s/it, loss=0.0264, acc=97.75%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0028, Acc: 99.51%, F1: 0.9951\n",
      "  Val   - Loss: 0.0264, Acc: 97.75%, F1: 0.9774\n",
      "  Learning Rate (group0): 6.06e-06\n",
      "  No improvement. Patience: 3/10\n",
      "\n",
      "Fold 5 - Epoch 24/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:19<00:00,  2.89s/it, loss=0.0114, acc=98.60%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0169, acc=98.03%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0114, Acc: 98.60%, F1: 0.9860\n",
      "  Val   - Loss: 0.0169, Acc: 98.03%, F1: 0.9804\n",
      "  Learning Rate (group0): 5.78e-06\n",
      "  No improvement. Patience: 4/10\n",
      "\n",
      "Fold 5 - Epoch 25/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:31<00:00,  3.02s/it, loss=0.0021, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:28<00:00,  1.22s/it, loss=0.0164, acc=98.88%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0021, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0164, Acc: 98.88%, F1: 0.9887\n",
      "  Learning Rate (group0): 5.50e-06\n",
      "  No improvement. Patience: 5/10\n",
      "\n",
      "Fold 5 - Epoch 26/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:47<00:00,  3.19s/it, loss=0.0020, acc=99.72%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:23<00:00,  1.03s/it, loss=0.0220, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0020, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0220, Acc: 98.88%, F1: 0.9887\n",
      "  Learning Rate (group0): 5.22e-06\n",
      "  No improvement. Patience: 6/10\n",
      "\n",
      "Fold 5 - Epoch 27/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:17<00:00,  2.87s/it, loss=0.0031, acc=99.72%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.08s/it, loss=0.0164, acc=98.31%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0031, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0164, Acc: 98.31%, F1: 0.9831\n",
      "  Learning Rate (group0): 4.94e-06\n",
      "  No improvement. Patience: 7/10\n",
      "\n",
      "Fold 5 - Epoch 28/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:27<00:00,  2.97s/it, loss=0.0017, acc=99.86%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.06s/it, loss=0.0133, acc=98.88%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0017, Acc: 99.86%, F1: 0.9986\n",
      "  Val   - Loss: 0.0133, Acc: 98.88%, F1: 0.9888\n",
      "  Learning Rate (group0): 4.66e-06\n",
      "  No improvement. Patience: 8/10\n",
      "\n",
      "Fold 5 - Epoch 29/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:31<00:00,  3.02s/it, loss=0.0016, acc=99.72%]\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:24<00:00,  1.08s/it, loss=0.0290, acc=97.47%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0016, Acc: 99.72%, F1: 0.9972\n",
      "  Val   - Loss: 0.0290, Acc: 97.47%, F1: 0.9745\n",
      "  Learning Rate (group0): 4.38e-06\n",
      "  No improvement. Patience: 9/10\n",
      "\n",
      "Fold 5 - Epoch 30/50\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [04:55<00:00,  3.28s/it, loss=0.0016, acc=99.79%] \n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:28<00:00,  1.25s/it, loss=0.0165, acc=98.60%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "  Train - Loss: 0.0016, Acc: 99.79%, F1: 0.9979\n",
      "  Val   - Loss: 0.0165, Acc: 98.60%, F1: 0.9860\n",
      "  Learning Rate (group0): 4.11e-06\n",
      "  No improvement. Patience: 10/10\n",
      "\n",
      "‚ö†Ô∏è Early stopping triggered!\n",
      "   Best score: 99.1573 at epoch 19\n",
      "\n",
      "‚ö†Ô∏è Early stopping at epoch 30\n",
      "\n",
      "üìä EVALUATING FOLD 5\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 23/23 [00:25<00:00,  1.11s/it, loss=0.0108, acc=99.16%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Fold 5 Validation Results:\n",
      "  Accuracy:         99.16%\n",
      "  Precision:        0.9916\n",
      "  Recall:           0.9916\n",
      "  F1 Score:         0.9916\n",
      "  Sensitivity (Normal):   0.9921\n",
      "  Sensitivity (Abnormal): 0.9913\n",
      "  Specificity (Normal):   0.9844\n",
      "  Specificity (Abnormal): 0.9956\n",
      "  Avg Sensitivity:  0.9917\n",
      "  Avg Specificity:  0.9900\n",
      "‚úì Confusion matrix saved\n",
      "\n",
      "======================================================================\n",
      "üìä K-FOLD CROSS-VALIDATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìà Cross-Validation Results (5 folds):\n",
      "  Accuracy:     99.05% ¬± 0.38%\n",
      "  Precision:    0.9905 ¬± 0.0037\n",
      "  Recall:       0.9905 ¬± 0.0038\n",
      "  F1 Score:     0.9905 ¬± 0.0038\n",
      "  Sensitivity:  0.9889 ¬± 0.0053\n",
      "  Specificity:  0.9905 ¬± 0.0029\n",
      "\n",
      "üèÜ Best Fold: 2 (Val Acc: 99.72%)\n",
      "\n",
      "======================================================================\n",
      "üß™ EVALUATING BEST MODEL ON HOLDOUT TEST SET\n",
      "======================================================================\n",
      "\n",
      "üìä Loading best model from Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:19<00:00,  1.47s/it, loss=0.0243, acc=96.48%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Test Set Results (Best Model from Fold 2):\n",
      "  Accuracy:         96.48%\n",
      "  Precision:        0.9656\n",
      "  Recall:           0.9648\n",
      "  F1 Score:         0.9650\n",
      "  Sensitivity (Normal):   0.9324\n",
      "  Sensitivity (Abnormal): 0.9840\n",
      "  Specificity (Normal):   0.9718\n",
      "  Specificity (Abnormal): 0.9609\n",
      "  Avg Sensitivity:  0.9582\n",
      "  Avg Specificity:  0.9664\n",
      "\n",
      "‚úì Test confusion matrix saved\n",
      "‚úì Results saved to CSV\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETE\n",
      "======================================================================\n",
      "\n",
      "üìä Final Summary:\n",
      "  Dataset: ERBMAHE (Abnormal vs Normal)\n",
      "  Strategy: Method 2 K-Fold with 10% Test Set\n",
      "  K-Fold CV Accuracy: 99.05% ¬± 0.38%\n",
      "  Test Set Accuracy:  96.48%\n",
      "  Test Set F1 Score:  0.9650\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ViT + CNN-CBAM + Fusion + Quantum Hybrid Network\n",
    "ERBMAHE Dataset Classification\n",
    "Binary Classification: Abnormal vs Normal\n",
    "\n",
    "METHOD 2 K-FOLD WITH SEPARATE TEST SET:\n",
    "- 10% holdout test set (never used during training)\n",
    "- K-Fold cross-validation on remaining 90%\n",
    "- Validation-based early stopping\n",
    "- Best fold model evaluated on test set\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import PyTorch & torchvision\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    from torchvision import transforms, models\n",
    "    print(\"‚úì PyTorch & torchvision imported successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error importing PyTorch/torchvision: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Transformers (ViT)\n",
    "try:\n",
    "    from transformers import ViTForImageClassification, ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Transformers...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers\"])\n",
    "    from transformers import ViTForImageClassification, ViTImageProcessor, ViTModel\n",
    "    print(\"‚úì Transformers installed successfully\")\n",
    "\n",
    "# PennyLane (quantum)\n",
    "try:\n",
    "    import pennylane as qml\n",
    "    print(\"‚úì PennyLane imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing PennyLane...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pennylane\"])\n",
    "    import pennylane as qml\n",
    "    print(\"‚úì PennyLane installed successfully\")\n",
    "\n",
    "# Check GPU\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA is not available. Please run this script on a machine with CUDA-enabled GPU and proper drivers.\")\n",
    "device = torch.device('cuda')\n",
    "print(f\"üîß Using device: {device}\")\n",
    "print(f\"üîß PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Config\n",
    "MODEL_NAME = \"google/vit-base-patch16-224\"\n",
    "CLASSES = ['Abnormal', 'Normal']\n",
    "N_QUBITS = 4\n",
    "N_FOLDS = 5\n",
    "\n",
    "# ============================================================================\n",
    "# ORIGINAL 2D-CBAM (Channel Attention + Spatial Attention)\n",
    "# ============================================================================\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.conv(x_cat)\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x * self.channel_attention(x)\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "# ============================================================================\n",
    "# CNN + CBAM BRANCH\n",
    "# ============================================================================\n",
    "class CNN_CBAM_Branch(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(CNN_CBAM_Branch, self).__init__()\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        self.cbam = CBAM(512, reduction=16, kernel_size=7)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        feat = self.cbam(feat)\n",
    "        feat = self.global_pool(feat)\n",
    "        feat = feat.view(feat.size(0), -1)\n",
    "        return feat\n",
    "\n",
    "# ============================================================================\n",
    "# Quantum Circuit & Layer\n",
    "# ============================================================================\n",
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits=4):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.dev = qml.device('default.qubit', wires=n_qubits)\n",
    "    \n",
    "    def circuit(self, inputs, weights):\n",
    "        for i in range(self.n_qubits):\n",
    "            qml.RX(inputs[i], wires=i)\n",
    "            qml.RZ(inputs[i], wires=i)\n",
    "        for i in range(self.n_qubits - 1):\n",
    "            qml.CRX(weights[i], wires=[i, i+1])\n",
    "        qml.CRX(weights[self.n_qubits-1], wires=[self.n_qubits-1, 0])\n",
    "        return [qml.expval(qml.PauliZ(i)) for i in range(self.n_qubits)]\n",
    "    \n",
    "    def create_qnode(self, weights):\n",
    "        @qml.qnode(self.dev, interface='torch')\n",
    "        def qnode(inputs):\n",
    "            return self.circuit(inputs, weights)\n",
    "        return qnode\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    def __init__(self, input_dim, n_qubits=4):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.feature_compress = nn.Linear(input_dim, n_qubits)\n",
    "        self.q_weights = nn.Parameter(torch.randn(n_qubits) * 0.01)\n",
    "        self.qc = QuantumCircuit(n_qubits)\n",
    "        self.feature_expand = nn.Linear(n_qubits, input_dim)\n",
    "        self.skip_alpha = nn.Parameter(torch.tensor(0.1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        batch_size = x.size(0)\n",
    "        x_compressed = self.feature_compress(x)\n",
    "        qnode = self.qc.create_qnode(self.q_weights)\n",
    "        q_out_list = []\n",
    "        for i in range(batch_size):\n",
    "            q_input = torch.tanh(x_compressed[i]) * np.pi\n",
    "            q_result = torch.stack(qnode(q_input))\n",
    "            q_result = q_result.float()\n",
    "            q_out_list.append(q_result)\n",
    "        q_out = torch.stack(q_out_list)\n",
    "        output = self.feature_expand(q_out)\n",
    "        output = output + self.skip_alpha * identity\n",
    "        return output\n",
    "\n",
    "# ============================================================================\n",
    "# Fusion Hybrid Model\n",
    "# ============================================================================\n",
    "class ViTQuantumHybrid(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=2, n_qubits=4):\n",
    "        super(ViTQuantumHybrid, self).__init__()\n",
    "        self.vit = ViTModel.from_pretrained(model_name)\n",
    "        vit_dim = self.vit.config.hidden_size\n",
    "        self.cnn_branch = CNN_CBAM_Branch(pretrained=True)\n",
    "        cnn_dim = 512\n",
    "        self.fusion_proj = nn.Linear(vit_dim + cnn_dim, vit_dim)\n",
    "        self.quantum_layer = QuantumLayer(vit_dim, n_qubits=n_qubits)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(vit_dim, vit_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(vit_dim // 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, pixel_values):\n",
    "        vit_out = self.vit(pixel_values=pixel_values)\n",
    "        vit_features = vit_out.last_hidden_state[:, 0]\n",
    "        cnn_features = self.cnn_branch(pixel_values)\n",
    "        fused = torch.cat([vit_features, cnn_features], dim=1)\n",
    "        fused = self.fusion_proj(fused)\n",
    "        quantum_features = self.quantum_layer(fused)\n",
    "        logits = self.classifier(quantum_features)\n",
    "        return logits\n",
    "\n",
    "# ============================================================================\n",
    "# Focal Loss\n",
    "# ============================================================================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - p_t) ** self.gamma * ce_loss\n",
    "        if self.alpha is not None:\n",
    "            if isinstance(self.alpha, (float, int)):\n",
    "                alpha_t = self.alpha\n",
    "            else:\n",
    "                alpha_t = self.alpha[targets]\n",
    "            focal_loss = alpha_t * focal_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "# ============================================================================\n",
    "# Early Stopping\n",
    "# ============================================================================\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, mode='max', verbose=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.best_epoch = 0\n",
    "    \n",
    "    def __call__(self, current_score, epoch):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì Initial best score: {current_score:.4f}\")\n",
    "            return False\n",
    "        if self.mode == 'max':\n",
    "            improved = current_score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            improved = current_score < (self.best_score - self.min_delta)\n",
    "        if improved:\n",
    "            self.best_score = current_score\n",
    "            self.best_epoch = epoch\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"  ‚úì New best score: {current_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"  No improvement. Patience: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                if self.verbose:\n",
    "                    print(f\"\\n‚ö†Ô∏è Early stopping triggered!\")\n",
    "                    print(f\"   Best score: {self.best_score:.4f} at epoch {self.best_epoch}\")\n",
    "        return self.early_stop\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET\n",
    "# ============================================================================\n",
    "class ERBMAHEDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor, augment=False):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.augment = augment\n",
    "        self.aug_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\n",
    "            transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.0),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'image_path']\n",
    "        label = self.df.loc[idx, 'class_id']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.augment:\n",
    "            image = self.aug_transform(image)\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        pixel_values = inputs['pixel_values'].squeeze(0)\n",
    "        return pixel_values, label\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN / VALIDATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for pixel_values, labels in pbar:\n",
    "        pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pixel_values)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = logits.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "            'acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for pixel_values, labels in pbar:\n",
    "            pixel_values, labels = pixel_values.to(device), labels.to(device)\n",
    "            logits = model(pixel_values)\n",
    "            loss = criterion(logits, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = logits.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss/(pbar.n+1):.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "    _, _, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    return running_loss / len(dataloader), 100. * correct / total, f1, all_preds, all_labels\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive metrics including sensitivity and specificity\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # For binary classification\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Sensitivity (Recall) for each class\n",
    "    sensitivity_class0 = tn / (tn + fn) if (tn + fn) > 0 else 0  # Normal\n",
    "    sensitivity_class1 = tp / (tp + fp) if (tp + fp) > 0 else 0  # Abnormal\n",
    "    \n",
    "    # Specificity for each class\n",
    "    specificity_class0 = tn / (tn + fp) if (tn + fp) > 0 else 0  # Normal\n",
    "    specificity_class1 = tp / (tp + fn) if (tp + fn) > 0 else 0  # Abnormal\n",
    "    \n",
    "    # Average\n",
    "    avg_sensitivity = (sensitivity_class0 + sensitivity_class1) / 2\n",
    "    avg_specificity = (specificity_class0 + specificity_class1) / 2\n",
    "    \n",
    "    # Overall metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy * 100,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'sensitivity_class0': sensitivity_class0,\n",
    "        'sensitivity_class1': sensitivity_class1,\n",
    "        'specificity_class0': specificity_class0,\n",
    "        'specificity_class1': specificity_class1,\n",
    "        'avg_sensitivity': avg_sensitivity,\n",
    "        'avg_specificity': avg_specificity,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"ViT + CNN-2D-CBAM + Fusion + Quantum Hybrid Network\")\n",
    "    print(\"ERBMAHE Dataset Classification\")\n",
    "    print(\"Binary Classification: Abnormal vs Normal\")\n",
    "    print(f\"METHOD 2: K-FOLD ({N_FOLDS} folds) WITH SEPARATE TEST SET (10%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    data_path = 'D:/training/archive/ICMR_datasets_ERBMAHE'\n",
    "\n",
    "    print(f\"\\nü§ñ Base Model: {MODEL_NAME}\")\n",
    "    print(f\"‚öõÔ∏è  Quantum Qubits: {N_QUBITS}\")\n",
    "    print(f\"üìä Classes: {CLASSES}\")\n",
    "    print(f\"üîÑ K-Fold: {N_FOLDS} folds on 90% data\")\n",
    "    print(f\"üß™ Test Set: 10% holdout\")\n",
    "\n",
    "    print(\"\\nüìÅ Loading dataset...\")\n",
    "    data_list = []\n",
    "    for class_name in CLASSES:\n",
    "        class_path = os.path.join(data_path, class_name)\n",
    "        if os.path.exists(class_path):\n",
    "            for img_file in os.listdir(class_path):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "                    data_list.append({\n",
    "                        'image_path': os.path.join(class_path, img_file),\n",
    "                        'label': class_name,\n",
    "                        'class_id': CLASSES.index(class_name)\n",
    "                    })\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: {class_path} not found!\")\n",
    "    \n",
    "    df = pd.DataFrame(data_list)\n",
    "    print(f\"üìä Total images: {len(df)}\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "\n",
    "    # Split: 90% for k-fold, 10% for final test\n",
    "    kfold_df, test_df = train_test_split(df, test_size=0.10, stratify=df['class_id'], random_state=42)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset split:\")\n",
    "    print(f\"  K-Fold data: {len(kfold_df)} ({len(kfold_df)/len(df)*100:.1f}%)\")\n",
    "    print(f\"  Test data:   {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "    # Class weights for focal loss (calculated on k-fold data)\n",
    "    class_counts = kfold_df['label'].value_counts().sort_index().values\n",
    "    total_samples = len(kfold_df)\n",
    "    class_weights = total_samples / (len(CLASSES) * class_counts)\n",
    "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "    print(f\"\\n‚öñÔ∏è Class weights for Focal Loss:\")\n",
    "    for i, class_name in enumerate(CLASSES):\n",
    "        print(f\"  {class_name}: {class_weights[i]:.4f}\")\n",
    "\n",
    "    # ViT processor\n",
    "    print(f\"\\nüîß Loading ViT processor...\")\n",
    "    processor = ViTImageProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # K-Fold setup\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_fold_histories = []\n",
    "    \n",
    "    batch_size = 16\n",
    "    num_epochs = 50\n",
    "\n",
    "    print(f\"\\n‚öôÔ∏è Training configuration:\")\n",
    "    print(f\"  Max epochs per fold: {num_epochs}\")\n",
    "    print(f\"  Batch size: {batch_size}\")\n",
    "    print(f\"  Early stopping patience: 10 epochs\")\n",
    "    print(f\"  Learning rate (ViT): 1e-5\")\n",
    "    print(f\"  Learning rate (CNN): 2e-4\")\n",
    "    print(f\"  Learning rate (Quantum): 5e-5\")\n",
    "    print(f\"  Learning rate (Classifier): 1e-4\")\n",
    "    print(f\"  Scheduler: CosineAnnealingLR\")\n",
    "    print(f\"  Loss: Focal Loss (gamma=2.0)\")\n",
    "    print(f\"  Strategy: Method 2 with separate test set\")\n",
    "\n",
    "    # ============================================================================\n",
    "    # K-FOLD CROSS-VALIDATION\n",
    "    # ============================================================================\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(skf.split(kfold_df, kfold_df['class_id'])):\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"FOLD {fold_idx + 1}/{N_FOLDS}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        train_df = kfold_df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = kfold_df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"\\nüìä Fold {fold_idx + 1} split:\")\n",
    "        print(f\"  Train:      {len(train_df)} ({len(train_df)/len(kfold_df)*100:.1f}% of k-fold data)\")\n",
    "        print(f\"  Validation: {len(val_df)} ({len(val_df)/len(kfold_df)*100:.1f}% of k-fold data)\")\n",
    "        \n",
    "        train_dataset = ERBMAHEDataset(train_df, processor=processor, augment=True)\n",
    "        val_dataset = ERBMAHEDataset(val_df, processor=processor, augment=False)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "        \n",
    "        print(f\"\\nü§ñ Creating model for Fold {fold_idx + 1}...\")\n",
    "        model = ViTQuantumHybrid(model_name=MODEL_NAME, num_classes=len(CLASSES), n_qubits=N_QUBITS).to(device)\n",
    "        \n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        \n",
    "        if fold_idx == 0:\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            quantum_params = sum(p.numel() for p in model.quantum_layer.parameters())\n",
    "            \n",
    "            print(f\"‚úì Total parameters: {total_params:,}\")\n",
    "            print(f\"‚úì Trainable parameters: {trainable_params:,}\")\n",
    "            print(f\"‚úì Quantum layer parameters: {quantum_params:,}\")\n",
    "            print(f\"‚úì Model size: {total_params * 4 / 1024 / 1024:.2f} MB\")\n",
    "        \n",
    "        def build_optimizer(model):\n",
    "            groups = []\n",
    "            vit_params = [p for p in model.vit.parameters() if p.requires_grad]\n",
    "            if vit_params:\n",
    "                groups.append({'params': vit_params, 'lr': 1e-5})\n",
    "            cnn_params = [p for p in model.cnn_branch.parameters() if p.requires_grad]\n",
    "            if cnn_params:\n",
    "                groups.append({'params': cnn_params, 'lr': 2e-4})\n",
    "            q_params = [p for p in model.quantum_layer.parameters() if p.requires_grad]\n",
    "            if q_params:\n",
    "                groups.append({'params': q_params, 'lr': 5e-5})\n",
    "            clf_params = [p for p in model.classifier.parameters() if p.requires_grad]\n",
    "            if clf_params:\n",
    "                groups.append({'params': clf_params, 'lr': 1e-4})\n",
    "            if not groups:\n",
    "                groups = [{'params': [p for p in model.parameters() if p.requires_grad], 'lr': 1e-4}]\n",
    "            return torch.optim.AdamW(groups, weight_decay=0.01)\n",
    "        \n",
    "        criterion = FocalLoss(alpha=class_weights, gamma=2.0, reduction='mean')\n",
    "        optimizer = build_optimizer(model)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "        early_stopping = EarlyStopping(patience=10, min_delta=0.001, mode='max', verbose=True)\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        fold_history = {\n",
    "            'train_loss': [], 'train_acc': [], 'train_f1': [],\n",
    "            'val_loss': [], 'val_acc': [], 'val_f1': []\n",
    "        }\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nFold {fold_idx + 1} - Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            train_loss, train_acc, train_f1 = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc, val_f1, _, _ = validate(model, val_loader, criterion, device)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            fold_history['train_loss'].append(train_loss)\n",
    "            fold_history['train_acc'].append(train_acc)\n",
    "            fold_history['train_f1'].append(train_f1)\n",
    "            fold_history['val_loss'].append(val_loss)\n",
    "            fold_history['val_acc'].append(val_acc)\n",
    "            fold_history['val_f1'].append(val_f1)\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"\\nResults:\")\n",
    "            print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.2f}%, F1: {train_f1:.4f}\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.2f}%, F1: {val_f1:.4f}\")\n",
    "            print(f\"  Learning Rate (group0): {current_lr:.2e}\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), f'fold{fold_idx+1}_best.pth')\n",
    "                print(f\"  üíæ Best model saved! (Val Acc: {best_val_acc:.2f}%)\")\n",
    "            \n",
    "            if early_stopping(val_acc, epoch):\n",
    "                print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        # Final validation evaluation\n",
    "        print(f\"\\nüìä EVALUATING FOLD {fold_idx + 1}\")\n",
    "        print(\"=\"*70)\n",
    "        model.load_state_dict(torch.load(f'fold{fold_idx+1}_best.pth'))\n",
    "        val_loss, val_acc, val_f1, y_pred, y_true = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        metrics = calculate_metrics(y_true, y_pred)\n",
    "        \n",
    "        print(f\"\\nüìà Fold {fold_idx + 1} Validation Results:\")\n",
    "        print(f\"  Accuracy:         {metrics['accuracy']:.2f}%\")\n",
    "        print(f\"  Precision:        {metrics['precision']:.4f}\")\n",
    "        print(f\"  Recall:           {metrics['recall']:.4f}\")\n",
    "        print(f\"  F1 Score:         {metrics['f1']:.4f}\")\n",
    "        print(f\"  Sensitivity (Normal):   {metrics['sensitivity_class0']:.4f}\")\n",
    "        print(f\"  Sensitivity (Abnormal): {metrics['sensitivity_class1']:.4f}\")\n",
    "        print(f\"  Specificity (Normal):   {metrics['specificity_class0']:.4f}\")\n",
    "        print(f\"  Specificity (Abnormal): {metrics['specificity_class1']:.4f}\")\n",
    "        print(f\"  Avg Sensitivity:  {metrics['avg_sensitivity']:.4f}\")\n",
    "        print(f\"  Avg Specificity:  {metrics['avg_specificity']:.4f}\")\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'val_acc': metrics['accuracy'],\n",
    "            'val_precision': metrics['precision'],\n",
    "            'val_recall': metrics['recall'],\n",
    "            'val_f1': metrics['f1'],\n",
    "            'val_sensitivity': metrics['avg_sensitivity'],\n",
    "            'val_specificity': metrics['avg_specificity'],\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'epochs_trained': len(fold_history['train_loss']),\n",
    "            'model_path': f'fold{fold_idx+1}_best.pth',\n",
    "            'y_true': y_true,\n",
    "            'y_pred': y_pred,\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        \n",
    "        all_fold_histories.append(fold_history)\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        cm = metrics['confusion_matrix']\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "        plt.title(f'Fold {fold_idx + 1} - Confusion Matrix\\n(Val Acc: {metrics[\"accuracy\"]:.2f}%)')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'fold{fold_idx+1}_confusion_matrix.png', dpi=150)\n",
    "        plt.close()\n",
    "        print(f\"‚úì Confusion matrix saved\")\n",
    "        \n",
    "        # Enhanced visualization for FIRST FOLD\n",
    "        if fold_idx == 0:\n",
    "            print(f\"\\nüìä Creating enhanced visualizations for Fold 1...\")\n",
    "            \n",
    "            # 1. Training/Validation curves\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "            epochs_range = range(1, len(fold_history['train_loss']) + 1)\n",
    "            \n",
    "            axes[0].plot(epochs_range, fold_history['train_loss'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[0].plot(epochs_range, fold_history['val_loss'], 'r-s', label='Val', linewidth=2, markersize=4)\n",
    "            axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[0].set_ylabel('Loss', fontsize=12)\n",
    "            axes[0].set_title('Fold 1 - Loss', fontsize=14, fontweight='bold')\n",
    "            axes[0].legend(fontsize=10)\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            axes[1].plot(epochs_range, fold_history['train_acc'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[1].plot(epochs_range, fold_history['val_acc'], 'r-s', label='Val', linewidth=2, markersize=4)\n",
    "            axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "            axes[1].set_title('Fold 1 - Accuracy', fontsize=14, fontweight='bold')\n",
    "            axes[1].legend(fontsize=10)\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            axes[2].plot(epochs_range, fold_history['train_f1'], 'b-o', label='Train', linewidth=2, markersize=4)\n",
    "            axes[2].plot(epochs_range, fold_history['val_f1'], 'r-s', label='Val', linewidth=2, markersize=4)\n",
    "            axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "            axes[2].set_ylabel('F1 Score', fontsize=12)\n",
    "            axes[2].set_title('Fold 1 - F1 Score', fontsize=14, fontweight='bold')\n",
    "            axes[2].legend(fontsize=10)\n",
    "            axes[2].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_training_curves.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Training curves saved\")\n",
    "            \n",
    "            # 2. Detailed confusion matrix\n",
    "            fig, ax = plt.subplots(figsize=(10, 8))\n",
    "            cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "            annotations = np.empty_like(cm).astype(str)\n",
    "            for i in range(cm.shape[0]):\n",
    "                for j in range(cm.shape[1]):\n",
    "                    annotations[i, j] = f'{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)'\n",
    "            sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues', \n",
    "                       xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "                       cbar_kws={'label': 'Count'}, ax=ax)\n",
    "            ax.set_title(f'Fold 1 - Detailed Confusion Matrix\\nVal Acc: {metrics[\"accuracy\"]:.2f}%', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "            ax.set_ylabel('True Label', fontsize=12)\n",
    "            ax.set_xlabel('Predicted Label', fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_confusion_detailed.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Detailed confusion matrix saved\")\n",
    "            \n",
    "            # 3. Metrics summary\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            metric_names = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Sensitivity', 'Specificity']\n",
    "            metric_values = [\n",
    "                metrics['accuracy'],\n",
    "                metrics['precision']*100,\n",
    "                metrics['recall']*100,\n",
    "                metrics['f1']*100,\n",
    "                metrics['avg_sensitivity']*100,\n",
    "                metrics['avg_specificity']*100\n",
    "            ]\n",
    "            colors = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c']\n",
    "            bars = ax.bar(metric_names, metric_values, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "            for bar, value in zip(bars, metric_values):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{value:.2f}%', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "            ax.set_ylabel('Score (%)', fontsize=12)\n",
    "            ax.set_title('Fold 1 - Validation Metrics Summary', fontsize=14, fontweight='bold')\n",
    "            ax.set_ylim([0, 105])\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            plt.xticks(rotation=15)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig('fold1_metrics_summary.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"  ‚úì Metrics summary saved\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SUMMARY ACROSS FOLDS\n",
    "    # ============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    accuracies = [r['val_acc'] for r in fold_results]\n",
    "    precisions = [r['val_precision'] for r in fold_results]\n",
    "    recalls = [r['val_recall'] for r in fold_results]\n",
    "    f1_scores = [r['val_f1'] for r in fold_results]\n",
    "    sensitivities = [r['val_sensitivity'] for r in fold_results]\n",
    "    specificities = [r['val_specificity'] for r in fold_results]\n",
    "    \n",
    "    print(f\"\\nüìà Cross-Validation Results ({N_FOLDS} folds):\")\n",
    "    print(f\"  Accuracy:     {np.mean(accuracies):.2f}% ¬± {np.std(accuracies):.2f}%\")\n",
    "    print(f\"  Precision:    {np.mean(precisions):.4f} ¬± {np.std(precisions):.4f}\")\n",
    "    print(f\"  Recall:       {np.mean(recalls):.4f} ¬± {np.std(recalls):.4f}\")\n",
    "    print(f\"  F1 Score:     {np.mean(f1_scores):.4f} ¬± {np.std(f1_scores):.4f}\")\n",
    "    print(f\"  Sensitivity:  {np.mean(sensitivities):.4f} ¬± {np.std(sensitivities):.4f}\")\n",
    "    print(f\"  Specificity:  {np.mean(specificities):.4f} ¬± {np.std(specificities):.4f}\")\n",
    "    \n",
    "    # Find best fold\n",
    "    best_fold_idx = np.argmax(accuracies)\n",
    "    best_fold = fold_results[best_fold_idx]\n",
    "    print(f\"\\nüèÜ Best Fold: {best_fold['fold']} (Val Acc: {best_fold['val_acc']:.2f}%)\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # EVALUATE BEST MODEL ON TEST SET\n",
    "    # ============================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üß™ EVALUATING BEST MODEL ON HOLDOUT TEST SET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìä Loading best model from Fold {best_fold['fold']}...\")\n",
    "    best_model = ViTQuantumHybrid(model_name=MODEL_NAME, num_classes=len(CLASSES), n_qubits=N_QUBITS).to(device)\n",
    "    best_model.load_state_dict(torch.load(best_fold['model_path']))\n",
    "    \n",
    "    test_dataset = ERBMAHEDataset(test_df, processor=processor, augment=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    test_loss, test_acc, test_f1, test_pred, test_true = validate(best_model, test_loader, criterion, device)\n",
    "    test_metrics = calculate_metrics(test_true, test_pred)\n",
    "    \n",
    "    print(f\"\\nüìà Test Set Results (Best Model from Fold {best_fold['fold']}):\")\n",
    "    print(f\"  Accuracy:         {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Precision:        {test_metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:           {test_metrics['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:         {test_metrics['f1']:.4f}\")\n",
    "    print(f\"  Sensitivity (Normal):   {test_metrics['sensitivity_class0']:.4f}\")\n",
    "    print(f\"  Sensitivity (Abnormal): {test_metrics['sensitivity_class1']:.4f}\")\n",
    "    print(f\"  Specificity (Normal):   {test_metrics['specificity_class0']:.4f}\")\n",
    "    print(f\"  Specificity (Abnormal): {test_metrics['specificity_class1']:.4f}\")\n",
    "    print(f\"  Avg Sensitivity:  {test_metrics['avg_sensitivity']:.4f}\")\n",
    "    print(f\"  Avg Specificity:  {test_metrics['avg_specificity']:.4f}\")\n",
    "    \n",
    "    # Test confusion matrix\n",
    "    test_cm = test_metrics['confusion_matrix']\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    test_cm_percent = test_cm.astype('float') / test_cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    test_annotations = np.empty_like(test_cm).astype(str)\n",
    "    for i in range(test_cm.shape[0]):\n",
    "        for j in range(test_cm.shape[1]):\n",
    "            test_annotations[i, j] = f'{test_cm[i, j]}\\n({test_cm_percent[i, j]:.1f}%)'\n",
    "    sns.heatmap(test_cm, annot=test_annotations, fmt='', cmap='Greens', \n",
    "               xticklabels=CLASSES, yticklabels=CLASSES,\n",
    "               cbar_kws={'label': 'Count'})\n",
    "    plt.title(f'Test Set Confusion Matrix\\n(Best Model from Fold {best_fold[\"fold\"]}, Acc: {test_metrics[\"accuracy\"]:.2f}%)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('test_confusion_matrix.png', dpi=150)\n",
    "    plt.close()\n",
    "    print(\"\\n‚úì Test confusion matrix saved\")\n",
    "    \n",
    "    # Save all results\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    results_df.to_csv('kfold_results.csv', index=False)\n",
    "    print(\"‚úì Results saved to CSV\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nüìä Final Summary:\")\n",
    "    print(f\"  Dataset: ERBMAHE (Abnormal vs Normal)\")\n",
    "    print(f\"  Strategy: Method 2 K-Fold with 10% Test Set\")\n",
    "    print(f\"  K-Fold CV Accuracy: {np.mean(accuracies):.2f}% ¬± {np.std(accuracies):.2f}%\")\n",
    "    print(f\"  Test Set Accuracy:  {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"  Test Set F1 Score:  {test_metrics['f1']:.4f}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
